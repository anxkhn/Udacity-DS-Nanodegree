WEBVTT
Kind: captions
Language: pt-BR

00:00:00.300 --> 00:00:03.868
No fim do último vídeo,
os dados foram processados

00:00:03.901 --> 00:00:06.234
e o modelo, especificado.

00:00:06.267 --> 00:00:09.801
Atualmente,
cerca de 600 mil pesos

00:00:09.834 --> 00:00:11.234
possuem valores aleatórios,

00:00:11.267 --> 00:00:13.567
portanto o modelo possui
previsão aleatória.

00:00:13.601 --> 00:00:16.334
Ao treinar o modelo,
nós alteramos os pesos

00:00:16.367 --> 00:00:18.467
e melhoramos as previsões.

00:00:18.501 --> 00:00:20.400
Mas, antes de treinarmos
o modelo,

00:00:20.434 --> 00:00:23.801
nós precisamos especificar
a função de perda.

00:00:23.834 --> 00:00:27.834
Como estamos construindo
o classificador multiclasse,

00:00:28.180 --> 00:00:32.200
nós utilizaremos a perda
de entropia cruzada categórica.

00:00:32.234 --> 00:00:35.934
Esta função de perda confere
se o modelo se saiu bem

00:00:35.968 --> 00:00:37.767
ao classificar uma imagem

00:00:37.801 --> 00:00:41.334
comparando a previsão dos modelos
com o rótulo verdadeiro.

00:00:41.367 --> 00:00:44.534
Os rótulos verdadeiros
são codificações one-hot

00:00:44.567 --> 00:00:47.801
e cada rótulo é um vetor
com dez entradas.

00:00:47.834 --> 00:00:51.634
O modelo fornece um vetor
também com dez entradas.

00:00:51.667 --> 00:00:55.000
Digamos que ele forneça
esta previsão.

00:00:55.033 --> 00:00:59.601
Ele prevê que haja um 8,
com 90% de probabilidade,

00:00:59.634 --> 00:01:02.968
e um 3,
com probabilidade de 10%.

00:01:03.767 --> 00:01:08.601
Você pode pensar no vetor
de rótulo como probabilidade.

00:01:08.634 --> 00:01:12.200
Ele sabe que há
100% de probabilidade

00:01:12.234 --> 00:01:14.300
que a imagem
represente um três.

00:01:15.100 --> 00:01:19.868
A perda de entropia cruzada
categórica observa os vetores

00:01:19.901 --> 00:01:21.601
e retorna um valor menor

00:01:21.634 --> 00:01:25.567
se os dois concordam
sobre o que há na imagem.

00:01:25.601 --> 00:01:29.567
Neste caso, o modelo diz
que é um 8,

00:01:29.601 --> 00:01:33.133
mas o rótulo tem certeza
de que é um 3.

00:01:33.167 --> 00:01:37.234
Nós teremos um valor
mais alto para a perda.

00:01:37.267 --> 00:01:40.701
Se o modelo retornar
este resultado,

00:01:40.734 --> 00:01:46.033
ele terá 90% de certeza
de que a imagem seja um 3,

00:01:46.067 --> 00:01:49.467
e a perda de entropia cruzada
categórica será mais baixa.

00:01:50.300 --> 00:01:56.100
Para resumir, se as previsões
do modelo concordam com o rótulo,

00:01:56.133 --> 00:01:57.868
a perda será mais baixa.

00:01:57.901 --> 00:02:00.200
É isso que nós queremos
em um bom modelo.

00:02:00.234 --> 00:02:03.534
Nós queremos que as previsões
concordem com o rótulo.

00:02:03.567 --> 00:02:06.234
Nós tentaremos encontrar
parâmetros do modelo

00:02:06.267 --> 00:02:09.701
que forneçam previsões
que minimizem a função de perda.

00:02:10.534 --> 00:02:12.000
Na lição anterior,

00:02:12.033 --> 00:02:14.501
você viu a função de perda

00:02:14.534 --> 00:02:17.400
como uma superfície
que lembrava uma montanha.

00:02:18.100 --> 00:02:20.467
Para minimizar esta função,

00:02:20.501 --> 00:02:23.334
nós precisamos
de uma forma para descer

00:02:23.367 --> 00:02:25.534
até a parte mais baixa.

00:02:25.567 --> 00:02:28.501
O método padrão para descer
a função de perda

00:02:28.534 --> 00:02:30.634
é chamada de gradiente
descendente.

00:02:30.667 --> 00:02:32.901
Você viu algumas formas

00:02:32.934 --> 00:02:35.167
de realizar o gradiente
descendente,

00:02:35.200 --> 00:02:39.167
e cada método no Keras possui
um otimizador correspondente.

00:02:39.200 --> 00:02:43.434
A superfície representada aqui
é um exemplo de função de perda,

00:02:43.467 --> 00:02:45.167
e todos os otimizadores

00:02:45.200 --> 00:02:48.100
estão seguindo
para o mínimo da função.

00:02:48.767 --> 00:02:51.667
Como você pode ver,
alguns funcionam melhor,

00:02:51.701 --> 00:02:55.767
então você deve testar todos
no seu código.

00:02:56.567 --> 00:02:59.434
Nesta lição, os exemplos
sempre utilizarão

00:02:59.467 --> 00:03:02.334
RMSProp como otimizador.

00:03:02.367 --> 00:03:03.968
Ao compilarmos a função,

00:03:04.000 --> 00:03:07.332
nós especificamos a função
de perda e o otimizador.

00:03:07.834 --> 00:03:09.734
Adicionando
o parâmetro adicional,

00:03:09.767 --> 00:03:11.801
com a precisão como métrica,

00:03:11.834 --> 00:03:13.167
nós poderemos conferir

00:03:13.200 --> 00:03:15.601
como a precisão do modelo
se altera

00:03:15.634 --> 00:03:18.033
durante o processo
de treinamento.

00:03:18.067 --> 00:03:19.534
Após compilar o modelo,

00:03:19.567 --> 00:03:21.868
nós podemos ver
qual tipo de precisão

00:03:21.901 --> 00:03:25.434
ele já possui no conjunto
de teste antes de treiná-lo.

00:03:26.267 --> 00:03:29.734
Não esperamos melhor desempenho
do que o aleatório,

00:03:29.767 --> 00:03:33.300
que, neste caso, corresponde
à precisão de um para dez

00:03:33.334 --> 00:03:35.300
ou de 10%.

00:03:35.334 --> 00:03:39.534
Nós tivemos precisão de 13%.

00:03:39.567 --> 00:03:43.133
Nós o treinaremos para melhorar
o desempenho na próxima lição.

