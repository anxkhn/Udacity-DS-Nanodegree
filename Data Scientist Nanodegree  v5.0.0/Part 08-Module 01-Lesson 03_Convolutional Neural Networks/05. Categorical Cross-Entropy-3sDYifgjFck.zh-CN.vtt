WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.370
在上个视频结束时

00:00:02.370 --> 00:00:06.298
我们处理了数据并指定了模型

00:00:06.299 --> 00:00:09.539
目前所有约 600,000 个权重

00:00:09.538 --> 00:00:13.719
都具有随机值 因此模型是随机预测结果

00:00:13.720 --> 00:00:15.118
通过训练模型

00:00:15.118 --> 00:00:18.605
我们将修改这些权重并改善预测结果

00:00:18.605 --> 00:00:20.535
但是在训练模型之前

00:00:20.535 --> 00:00:24.179
我们需要指定损失函数

00:00:24.178 --> 00:00:27.853
因为我们构建的是多类别分类器

00:00:27.855 --> 00:00:32.380
因此将使用分类交叉熵损失

00:00:32.380 --> 00:00:36.149
该损失函数通过将模型的预测结果与实际标签进行对比

00:00:36.149 --> 00:00:41.603
看看我们的模型是否能够很好地分类图片

00:00:41.603 --> 00:00:43.649
注意 真正的标签是一位one-hot 编码

00:00:43.649 --> 00:00:47.975
每个标签是具有 10 个项目的向量

00:00:47.975 --> 00:00:51.000
模型输出向量也是 10 个项目

00:00:51.000 --> 00:00:54.795
假设模型返回这个预测结果

00:00:54.795 --> 00:00:57.689
它预测图片中的数字是 8 的概率是 90%

00:00:57.689 --> 00:01:03.975
是 3 的概率是 10%

00:01:03.975 --> 00:01:08.530
实际上 你还可以将标签向量看做概率

00:01:08.530 --> 00:01:15.129
它知道图片有 100% 的概率描绘的是 3

00:01:15.129 --> 00:01:19.813
分类交叉熵损失查看这两个向量

00:01:19.813 --> 00:01:25.689
如果这两个向量对图片中的数字保持相同的意见 那么返回一个较低的值

00:01:25.688 --> 00:01:29.573
这里 模型非常确定数字是 8

00:01:29.572 --> 00:01:33.464
但是标签很确定数字是 3

00:01:33.465 --> 00:01:37.245
因此损失函数将返回一个更高的值

00:01:37.245 --> 00:01:40.459
如果模型稍后返回这个输出

00:01:40.459 --> 00:01:45.909
并改为 90% 确定图片中的数字是 3

00:01:45.909 --> 00:01:50.536
那么分类交叉熵损失将更低

00:01:50.537 --> 00:01:55.974
总结下 我们看到如果模型预测结果与标签的一致

00:01:55.974 --> 00:01:57.880
那么损失很低

00:01:57.879 --> 00:02:00.198
我们对好的模型也是这种期望

00:02:00.200 --> 00:02:03.155
我们希望预测结果与标签的一致

00:02:03.155 --> 00:02:06.405
我们将尝试寻找使预测结果 

00:02:06.405 --> 00:02:09.519
能够最小化损失函数的模型参数

00:02:09.519 --> 00:02:11.974
在上节课

00:02:11.973 --> 00:02:13.657
我们让大家将损失函数

00:02:13.657 --> 00:02:17.708
想象成代表山峦的表面

00:02:17.710 --> 00:02:20.675
要最小化该函数

00:02:20.675 --> 00:02:25.724
我们只需找到降落到最低山谷的道路

00:02:25.723 --> 00:02:30.838
降低损失函数的标准方法是梯度下降

00:02:30.840 --> 00:02:33.628
我们介绍了几种实现梯度下降的方法

00:02:33.627 --> 00:02:39.578
在 Keras 中每种方法都对应一个优化程序

00:02:39.580 --> 00:02:43.344
这里描绘的表面是一种损失函数示例

00:02:43.342 --> 00:02:48.817
所有优化程序都希望获得函数最小值

00:02:48.818 --> 00:02:52.168
可以看出 有些优化程序的效果比其他的更好

00:02:52.169 --> 00:02:56.539
建议你在代码中实验所有这些优化程序

00:02:56.538 --> 00:03:02.513
在这节课 示例将始终使用 RMSProp 作为优化程序

00:03:02.514 --> 00:03:04.064
当我们编译该函数时

00:03:04.062 --> 00:03:07.804
我们将指定损失函数和优化程序

00:03:07.805 --> 00:03:11.715
通过将这个额外参数添加为准确率指标

00:03:11.715 --> 00:03:18.039
我们将能够检查我们的模型准确率在训练流程中是如何变化的

00:03:18.038 --> 00:03:19.618
编译模型后

00:03:19.620 --> 00:03:22.395
我们可以先查看对于测试集

00:03:22.395 --> 00:03:26.375
它已经具备的准确率 然后再去训练它

00:03:26.375 --> 00:03:29.639
我们并不期望它比随机情况效果更好

00:03:29.639 --> 00:03:35.400
这里对应的是 10% 的准确率

00:03:35.400 --> 00:03:39.425
耶！我们达到了 13% 的准确率

00:03:39.425 --> 00:03:43.000
我们将在下节课对其进行训练 使其效果好很多

