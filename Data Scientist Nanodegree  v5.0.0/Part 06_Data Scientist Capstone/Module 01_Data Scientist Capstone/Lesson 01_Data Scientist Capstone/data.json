{
  "data": {
    "lesson": {
      "id": 698684,
      "key": "d6285247-6bc0-4783-b118-6f41981b9469",
      "title": "Data Scientist Capstone",
      "semantic_type": "Lesson",
      "is_public": true,
      "version": "1.0.0",
      "locale": "en-us",
      "summary": "Now you will put your Data Science skills to the test by solving a real world problem using all that you have learned throughout the program.",
      "lesson_type": "Classroom",
      "display_workspace_project_only": false,
      "resources": {
        "files": [
          {
            "name": "Videos Zip File",
            "uri": "https://zips.udacity-data.com/d6285247-6bc0-4783-b118-6f41981b9469/698684/1540840400100/Data+Scientist+Capstone+Videos.zip"
          },
          {
            "name": "Transcripts Zip File",
            "uri": "https://zips.udacity-data.com/d6285247-6bc0-4783-b118-6f41981b9469/698684/1540840397421/Data+Scientist+Capstone+Subtitles.zip"
          }
        ],
        "google_plus_link": null,
        "career_resource_center_link": null,
        "coaching_appointments_link": null,
        "office_hours_link": null,
        "aws_provisioning_link": null
      },
      "project": {
        "key": "08004df4-bae6-416e-946b-b5ffae01bdb1",
        "version": "1.0.0",
        "locale": "en-us",
        "duration": 50400,
        "semantic_type": "Project",
        "title": "Capstone Project",
        "description": "### Before you submit:\n\nYour project needs to **Meet Specifications** in all categories of the [Project Rubric](https://review.udacity.com/#!/rubrics/2345/view) in order to pass. So before you submit, do a self-assessment of your work using the rubric, and you'll probably find some revisions you want to make first. \n\nIf you submit a web application, you only need to submit a link to your Github repository. In this case, since you won't be writing up a separate report, you need to make sure to address the Project Definition, Analysis, and Conclusion sections of the rubric in your README file, or in your Jupyter Notebook if you provide one.\n\nIf you submit a blog post, you will need to submit two links - one for your GitHub repo and one for your blog post. The audience for your blog post should be that of a **technical audience member**. Your GitHub repo should contain your code (if possible), dataset (unless you chose the Spark project option), and README.md files. \n\nIt can take us up to a week to grade the project, but in most cases it is much faster. You will get an email once your submission has been reviewed. In the meantime, you should feel free to proceed with your learning journey by continuing on to the next module in the program.",
        "is_public": true,
        "summary": null,
        "forum_path": "",
        "rubric_id": "2345",
        "terminal_project_id": null,
        "resources": null,
        "image": null
      },
      "lab": null,
      "concepts": [
        {
          "id": 737583,
          "key": "0c044d83-dd4a-410e-8176-2a4452bc3a74",
          "title": "Introduction",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "0c044d83-dd4a-410e-8176-2a4452bc3a74",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 752128,
              "key": "d718908b-7dfa-4075-945c-03bd73231497",
              "title": "Capstone",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "jewlarqqbTo",
                "china_cdn_id": "jewlarqqbTo.mp4"
              }
            }
          ]
        },
        {
          "id": 698685,
          "key": "d8543be3-078b-406e-a0f5-6c755b8c7d0a",
          "title": "Project Overview",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "d8543be3-078b-406e-a0f5-6c755b8c7d0a",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 708059,
              "key": "4ca15645-75b9-484d-bd78-358fb6406a21",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Build Your Data Science Project\n\nIn this capstone project, you will leverage what you’ve learned throughout the program to build a data\nscience project of your choosing. Your project deliverables are:\n\n1. A Github repository of your work.\n2. A blog (or other medium for a write-up) post written for a technical audience, or a deployed web application powered by data.\n\nYou'll follow the steps of the data science process that we've discussed:\n\n1. You will first **define** the problem you want to solve and investigate potential solutions. \n2. Next, you will **analyze** the problem through visualizations and data exploration to have a better understanding of what algorithms and features are appropriate for solving it. \n3. You will then **implement** the algorithms and metrics of your choice, documenting the preprocessing, refinement, and post-processing steps along the way. \n4. Afterwards, you will collect **results** about your findings, visualize significant quantities, validate/justify your results, and make any concluding remarks about whether your implementation adequately solves the problem. \n5. Finally, you will **construct** a blog post (or other medium for a write-up) to document all of the steps from start to finish of your project, or deploy your results into a web application.\n\n### Setting Yourself Apart\nAn important part of landing a job or advancing your career as a data scientist is setting yourself apart through impressive data science projects. By now, you've completed several guided projects, and now's your chance to show off your skills and creativity. You'll receive a review of your project with feedback from a Udacity mentor, and they will focus on how your project demonstrates your skills as a well-rounded data scientist.\n\nThis project is designed to prepare you for delivering a polished, end-to-end solution report of a real-world problem in a field of interest. When developing new technology, or deriving adaptations of previous technology, properly documenting your process is critical for both validating and replicating your results.\n\nThings you will learn by completing this project:\n- How to research and investigate a real-world problem of interest.\n- How to accurately apply specific data science algorithms and techniques.\n- How to properly analyze and visualize your data and results for validity.\n- How to document and write a report of your work.\n\n\n",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 737610,
          "key": "e7564df5-2487-4b08-b476-68716603047f",
          "title": "Software & Data Requirements",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "e7564df5-2487-4b08-b476-68716603047f",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 737612,
              "key": "b314472c-cc7c-4871-9e3a-019eef299cbe",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "## Software Requirements\n**Your project must be written in Python 3.x**. Given the free-form nature of the data scientist capstone, the software and libraries you will need to successfully complete your work will vary depending on the chosen application area and problem definition. Because of this, it is imperative that all necessary software and libraries used in your capstone project are accessible to the reviewer and clearly documented. Information regarding the software and libraries that your project makes use of should be included in your `README` document in your GitHub repo, along with your submission. Please note that proprietary software, software that requires private licenses, or software behind a paywall or login account should be avoided.\n\n## Data Requirements\nEvery data scientist capstone project will most certainly require some form of dataset or input data structure (input text files, images, etc.). Similar to the software requirements above, the data you use must either be publicly accessible or provided by you during the submission process, and private or proprietary data should not be used without expressed permission. Please take into consideration the file size of your data — while there is no strict upper limit, input files that are excessively large may require reviewers longer than an acceptable amount of time to acquire all of your project files and/or execute the provided development code. This can take away from the reviewer's time that could be put towards evaluating your submission. If the data you are working with fits the criteria of being too large, consider whether you can work with a subset of the data instead, or provide a representative sample of the data which the reviewer may use to verify the solution explored in the project.\n\n## Ethics\nUdacity's A/B Testing course has a segment that discusses [the sensitivity of data](https://classroom.udacity.com/courses/ud257/lessons/3998098714/concepts/39997087540923#) (free course link) and the expectation of privacy from those whose information has been collected. While most data you find has been made available to the public will not have any ethical complications, it is extremely important that you are considering where the data you are using came from, and whether that data contains any sensitive information. For example, if you worked for a bank and wanted to use customers' bank statements as part of your project, this would most likely be an unethical choice of data and should be avoided.\n\n## Note on Spark Project\nNot all of these instructions regarding software and data requirements apply if you choose the Spark project option, which comes with its own separate set of software and data requirements. You can find more details on this in the Spark course content in the Extracurriculars section of your classroom.",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 751863,
          "key": "dcfb8634-9e75-4479-aa98-bac101e60f7c",
          "title": "Possible Projects",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "dcfb8634-9e75-4479-aa98-bac101e60f7c",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 751864,
              "key": "b3787bce-892f-492c-b370-e989f0013d3f",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Selecting a Project\n\nThink about a technical field or domain that you are passionate about, such as robotics, virtual reality, finance, natural language processing, or even artificial intelligence (the possibilities are endless!). Then, choose an existing problem within that domain that you are interested in which you could solve by applying data science techniques. Be sure that you have collected all of the resources needed (such as a dataset) to complete this project, and make the appropriate citations wherever necessary in GitHub (and your blog, if that is the path you decide to pursue). Below are a few suggested problem areas you could explore if you are unsure what your passion is:\n\n- [Robot Motion Planning](https://docs.google.com/document/d/1ZFCH6jS3A5At7_v5IUM5OpAXJYiutFuSIjTzV_E-vdE/pub)\n- [Healthcare](https://docs.google.com/document/d/1WzurKKa9AX2DnOH7KiB38mvozdOSemfkGpex8hdTy8c/pub)\n- [Computer Vision](https://docs.google.com/document/d/1y-XfjkPFgUQxFIQ9bBncUSjs4HOf5E-45FrLYNBsZb4/pub)\n- [Education](https://docs.google.com/document/d/1vjerjRQnWs1kLbZagDYT6rNqiwAG23Yj45oUY88IAxI/pub)\n- [Investment and Trading](https://docs.google.com/document/d/1ycGeb1QYKATG6jvz74SAMqxrlek9Ed4RYrzWNhWS-0Q/pub)\n\nIn addition, you may find a technical domain (along with the problem and dataset) in a *competition* on platforms such as [Kaggle](http://kaggle.com), or [Devpost](http://devpost.com). This can be helpful for discovering a particular problem you may be interested in solving as an alternative to the suggested problem areas above. In many cases, some of the requirements for the capstone project are already defined for you when choosing from these platforms. \n\n#### Udacity Specific Projects\n\n * **Customer Segmentation Report for Arvato Financial Services**<br />\n\n * **Optimizing App Offers With Starbucks**<br />\n\n* **Use Convolutional Neural Networks to Identify Dog Breeds** <br>*(If you decide to complete this project, you can find additional content to assist in the extra-curricular portion of this program)*.\n\n\n* **Using Spark to Predict Churn with Insight Data Science** <br>\n*(If you decide to complete this project, you can find a series of Spark lessons in the extra-curricular portion of your classroom, as well as a Spark Project Overview and Spark Project Workspace later in this Capstone Project module.)*\n\n#### Check out Sample Projects\n\n* Here are two projects originally created for the Machine Learning Engineer Nanodegree program, but which give you an idea of what a final blog post might look like. Each of these meets the requirements for the capstone project for the Data Scientist Nanodegree: [sample project 1](https://github.com/udacity/machine-learning/blob/master/projects/capstone/report-example-1.pdf) and [sample project 2](https://github.com/udacity/machine-learning/blob/master/projects/capstone/report-example-3.pdf).\n\nIt isn't necessary that your project be 10 or 20 pages.  Rather, you should aim to solve a problem that interests you, build a project you are proud of, and explain your results to a technical audience.  The details of how you decide to do this are largely up to you but do use the rubric linked below to make sure your project meets specifications.  This is intended to be an open-ended project that allows you to apply what you have learned to your own area of interest.\n\nNo matter what project you decide to complete, you will want to check your work against the [project rubric here](https://review.udacity.com/#!/rubrics/2345/view).  \n\n\n",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 722568,
          "key": "8400bad9-69b4-4455-826c-177d90752f00",
          "title": "Bertelsmann/Arvato Project Overview",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "8400bad9-69b4-4455-826c-177d90752f00",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 769537,
              "key": "45e4f50a-f776-4190-95b9-4ced442b86d2",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Create a Customer Segmentation Report for Arvato Financial Solutions\n\nTo introduce yourself to the scenario you'll be investigating in this capstone project option, take a look at the following video with Timo Reis from Arvato Financial Solutions.",
              "instructor_notes": ""
            },
            {
              "id": 737646,
              "key": "6a23b819-bc51-4ad4-8deb-b5bd9288d642",
              "title": "Arvato Final Project",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "qBR6A0IQXEE",
                "china_cdn_id": "qBR6A0IQXEE.mp4"
              }
            },
            {
              "id": 722579,
              "key": "a44f05c3-7be2-4981-bce0-c7c62455b060",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "\n## Steps to Complete This Project\nThe project has three major steps: the customer segmentation report, the supervised learning model, and the Kaggle Competition.\n\n#### 1. Customer Segmentation Report\nYou'll begin the project by using unsupervised learning methods to analyze attributes of established customers and the general population in order to create customer segments.\n\n#### 2. Supervised Learning Model\nYou'll have access to a third dataset with attributes from targets of a mail order campaign. You'll use the previous analysis to build a machine learning model that predicts whether or not each individual will respond to the campaign.\n\n#### 3. Kaggle Competition\nOnce you've chosen a model, you'll use it to make predictions on the campaign data as part of a Kaggle Competition. You'll rank the individuals by how likely they are to convert to being a customer, and see how your modeling skills measure up against your fellow students.",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 671788,
          "key": "bea4372b-5c40-4030-b324-9b2c291e55ae",
          "title": "Arvato: Terms and Conditions",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "bea4372b-5c40-4030-b324-9b2c291e55ae",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 671790,
              "key": "a3c13ab9-3188-4c41-ad00-9b74080194f1",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Terms & Conditions\n\nIn addition to Udacity's Terms of Use and other policies, your\ndownloading and use of the **AZ Direct GmbH** data solely for use in the\n**Unsupervised Learning** and **Bertelsmann Capstone** projects are\ngoverned by the following additional terms and conditions. The big takeaways:\n\n1. You agree\nto **AZ Direct GmbH's** General Terms provided below and that you only\nhave the right to download and use the **AZ Direct GmbH** data solely to\ncomplete the data mining task which is part of the **Unsupervised\nLearning** and **Bertelsmann Capstone** projects for the Udacity Data\nScience Nanodegree program. \n\n2. You are prohibited from using the **AZ\nDirect GmbH** data in any other context. \n\n3. You are also required and\nhereby represent and warrant that you will delete any and all data you\ndownloaded within 2 weeks after your completion of the **Unsupervised\nLearning** and **Bertelsmann Capstone** projects and the program. \n4. If you\ndo not agree to these additional terms, you will not be allowed to\naccess the data for this project.\n\nThe full terms are provided in the workspace below.  You will then be asked in the next workspace to agree to these terms before gaining access to the project, which you may also choose to download if you would like to read in full the terms.\n\nThese same exact terms are provided in the next workspace, where you will be asked to accept the terms prior to gaining access to the data.",
              "instructor_notes": ""
            },
            {
              "id": 671792,
              "key": "265d09c1-437c-4961-b6d6-980e8bbbea18",
              "title": null,
              "semantic_type": "WorkspaceAtom",
              "is_public": true,
              "workspace_id": "viewBkemTRVpM7",
              "pool_id": "jupyter",
              "view_id": "jupyter-rJ7a0E6fX",
              "gpu_capable": false,
              "configuration": {
                "id": "reserved",
                "blueprint": {
                  "conf": {
                    "disk": null,
                    "ports": [],
                    "allowGrade": false,
                    "allowSubmit": false,
                    "defaultPath": ""
                  },
                  "kind": "jupyter"
                },
                "workspaceId": "reserved"
              },
              "starter_files": null
            }
          ]
        },
        {
          "id": 751856,
          "key": "e9553619-113b-4565-a34e-a9ef450659de",
          "title": "Bertelsmann/Arvato Project Workspace",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "e9553619-113b-4565-a34e-a9ef450659de",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 759885,
              "key": "fc29f5bf-c7c3-4a9e-bc3e-4d5f3c3ce60a",
              "title": null,
              "semantic_type": "WorkspaceAtom",
              "is_public": true,
              "workspace_id": "viewqk2nn0jlef",
              "pool_id": "jupyter",
              "view_id": "jupyter-bwokrwvgyrr",
              "gpu_capable": false,
              "configuration": {
                "id": "reserved",
                "blueprint": {
                  "conf": {
                    "disk": {
                      "id": "data-science-datasets",
                      "paths": [
                        {
                          "src": "/",
                          "dest": "/data/"
                        }
                      ]
                    },
                    "ports": [],
                    "allowGrade": false,
                    "allowSubmit": false,
                    "defaultPath": "/"
                  },
                  "kind": "jupyter"
                },
                "workspaceId": "reserved"
              },
              "starter_files": null
            }
          ]
        },
        {
          "id": 751853,
          "key": "480e9dc2-4726-4582-81d7-3b8e6a863450",
          "title": "Starbucks Project Overview",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "480e9dc2-4726-4582-81d7-3b8e6a863450",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 759711,
              "key": "b117d163-7035-4e37-a980-12938a0235b2",
              "title": "Capstone",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "bq-H7M5BU3U",
                "china_cdn_id": "bq-H7M5BU3U.mp4"
              }
            },
            {
              "id": 759986,
              "key": "4f09bdca-39ec-4322-8031-92a40808c3ec",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Starbuck's Capstone Challenge\n\nInstructions for the project can be found in the Starbucks Project Workspace.\n\n## Dataset overview\n\n- The program used to create the data simulates how people make purchasing\n  decisions and how those decisions are influenced by promotional offers.\n- Each person in the simulation has some hidden traits that influence their\n  purchasing patterns and are associated with their observable traits. People\n  produce various events, including receiving offers, opening offers, and making\n  purchases.\n- As a simplification, there are no explicit products to track. Only the\n  amounts of each transaction or offer are recorded.\n- There are three types of offers that can be sent: buy-one-get-one (BOGO),\n  discount, and informational. In a BOGO offer, a user needs to spend a certain\n  amount to get a reward equal to that threshold amount. In a discount, a user\n  gains a reward equal to a fraction of the amount spent. In an informational\n  offer, there is no reward, but neither is there a requisite amount that the user\n  is expected to spend. Offers can be delivered via multiple channels.\n- The basic task is to use the data to identify which groups of people are most\n  responsive to each type of offer, and how best to present each type of offer.\n\n## Data Dictionary\n\n### profile.json\n\nRewards program users (17000 users x 5 fields)\n\n- gender: (categorical) M, F, O, or null\n- age: (numeric) missing value encoded as 118\n- id: (string/hash)\n- became_member_on: (date) format YYYYMMDD\n- income: (numeric)\n\n### portfolio.json\n\nOffers sent during 30-day test period (10 offers x 6 fields)\n\n- reward: (numeric) money awarded for the amount spent\n- channels: (list) web, email, mobile, social\n- difficulty: (numeric) money required to be spent to receive reward\n- duration: (numeric) time for offer to be open, in days\n- offer_type: (string) bogo, discount, informational\n- id: (string/hash)\n\n### transcript.json\n\nEvent log (306648 events x 4 fields)\n\n- person: (string/hash)\n- event: (string) offer received, offer viewed, transaction, offer completed\n- value: (dictionary) different values depending on event type\n  - offer id: (string/hash) not associated with any \"transaction\"\n  - amount: (numeric) money spent in \"transaction\"\n  - reward: (numeric) money gained from \"offer completed\"\n- time: (numeric) hours after start of test",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 751859,
          "key": "59623bdf-9fdf-4b34-a5f8-c56dc75fc512",
          "title": "Starbucks Project Workspace",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "59623bdf-9fdf-4b34-a5f8-c56dc75fc512",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 760006,
              "key": "e731721a-45c9-421f-9527-b6c716e76247",
              "title": null,
              "semantic_type": "WorkspaceAtom",
              "is_public": true,
              "workspace_id": "view98n6mw6nlkh",
              "pool_id": "jupyter",
              "view_id": "jupyter-d3j7fvxar18",
              "gpu_capable": false,
              "configuration": {
                "id": "reserved",
                "blueprint": {
                  "conf": {
                    "disk": null,
                    "ports": [],
                    "allowGrade": false,
                    "allowSubmit": false,
                    "defaultPath": "/notebooks/Starbucks_Capstone_notebook.ipynb"
                  },
                  "kind": "jupyter"
                },
                "workspaceId": "reserved"
              },
              "starter_files": null
            }
          ]
        },
        {
          "id": 751860,
          "key": "fb0d6d8c-66a4-4fe8-835e-367db57d62ed",
          "title": "Dog Breed Classifier Overview",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "fb0d6d8c-66a4-4fe8-835e-367db57d62ed",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 751861,
              "key": "e5b3c0f9-fbed-4fab-8a2a-04eaf56e8d57",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "## Project Overview\n\nWelcome to the dog breed classifier project.  This project uses Convolutional Neural Networks (CNNs)!  In this project, you will learn how to build a pipeline to process real-world, user-supplied images.  Given an image of a dog, your algorithm will identify an estimate of the canine’s breed.  If supplied an image of a human, the code will identify the resembling dog breed.  \n\nIf you choose to complete this project, there are additional lessons in the extracurricular section of the classroom that you will likely find useful.  \n\n### Reminder\n\nIf you choose to complete the dog breed classifier project, you still must meet expectations for all the [Rubric](https://review.udacity.com/#!/rubrics/2345/view) items associated with the Data Scientist Capstone project.  That is, you still must deploy your code into an application, or you must write a post to be shared about the technical details of your analysis.  The workspace on the next page walks you through one possible solution, but you are welcome to discuss other solutions that are much different.  ",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 752228,
          "key": "f5d02322-c4fa-4626-a587-26f51aa3087d",
          "title": "Dog Breed Workspace",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "f5d02322-c4fa-4626-a587-26f51aa3087d",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 752229,
              "key": "58c4a918-8a26-466d-bc50-5c6bb0ad5717",
              "title": null,
              "semantic_type": "WorkspaceAtom",
              "is_public": true,
              "workspace_id": "viewooizm3ck72",
              "pool_id": "jupytergpu",
              "view_id": "jupyter-dw9u23ujmzn",
              "gpu_capable": true,
              "configuration": {
                "id": "reserved",
                "blueprint": {
                  "conf": {
                    "disk": {
                      "id": "mldatasets",
                      "paths": [
                        {
                          "src": "/dog_project",
                          "dest": "/data/"
                        }
                      ]
                    },
                    "ports": [],
                    "allowGrade": false,
                    "allowSubmit": false,
                    "defaultPath": "/notebooks/dog-project/dog_app.ipynb"
                  },
                  "kind": "jupyter"
                },
                "workspaceId": "reserved"
              },
              "starter_files": null
            }
          ]
        },
        {
          "id": 793381,
          "key": "47d96c80-82da-4640-9fff-54415f2a21df",
          "title": "Spark Project Overview",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "47d96c80-82da-4640-9fff-54415f2a21df",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 793391,
              "key": "f4ec2448-ff28-474b-aa8c-12ce94ea7f63",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Spark Project: Sparkify\n",
              "instructor_notes": ""
            },
            {
              "id": 793390,
              "key": "f8d4c379-44f1-4193-921e-49e9e548c259",
              "title": "L0 04 Project V2",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "lPCzCEG2yRs",
                "china_cdn_id": "lPCzCEG2yRs.mp4"
              }
            },
            {
              "id": 793392,
              "key": "4f66768b-0f9e-4905-86ee-d62a5293048c",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# What will I learn?\nYou'll learn how to manipulate large and realistic datasets with Spark to engineer relevant features for predicting churn. You'll learn how to use Spark MLlib to build machine learning models with large datasets, far beyond what could be done with non-distributed technologies like scikit-learn.\n\n### Career Relevance\nPredicting churn rates is a challenging and common problem that data scientists and analysts regularly encounter in any customer-facing business. Additionally, the ability to efficiently manipulate large datasets with Spark is one of the highest-demand skills in the field of data. \n\n### Essential Skills\n- Load large datasets into Spark and manipulate them using Spark SQL and Spark Dataframes\n- Use the machine learning APIs within Spark ML to build and tune models\n- Integrate the skills you've learned in the Spark course and the Data Scientist Nanodegree program\n\n# Take the Spark Course\nYou can find the Spark course in your Extracurriculars section [here](https://classroom.udacity.com/nanodegrees/nd025/parts/3e1c3447-39e1-476e-a5f3-8822fa52f9a3).",
              "instructor_notes": ""
            },
            {
              "id": 793393,
              "key": "663d4dc0-1137-4f63-916a-6570e343c957",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Project Instructions\nThe full dataset is 12GB, of which you can analyze a mini subset in the workspace on the following page. Optionally, you can choose to follow the instructions in the Extracurricular course to deploy a Spark cluster on the cloud using AWS or IBM Cloud to analyze a larger amount of data. Currently we have the full 12GB dataset available to you if you use AWS. If you use IBM, you can download a medium sized dataset to upload to your cluster.\n\nDetails on how to do this using AWS or IBM Cloud are included in the last lesson of the Extracurricular Spark Course content linked above. Note that this part is optional, and you will not receive credits to fund your deployment. You can do the IBM portion for free. Using AWS will cost you around $30 if you run a cluster up for a week with the settings we provide.\n\nOnce you've built your model, either in the classroom workspace or in the cloud with AWS or IBM, download your notebook and complete the remaining components of your Data Scientist Capstone project, including thorough documentation in a README file in your Github repository, as well as a web app or blog post explaining the technical details of your project. Be sure to review the [Project Rubric](https://review.udacity.com/#!/rubrics/2345/view) thoroughly before submitting your project.\n\n# Submission Instructions\nCreate a GitHub repository for this project, containing your notebook and README file. Once your project is finished, submit the URL of this repository.\n\n# Useful Links\n[Udacity Project FAQ](https://review.udacity.com/#!/submissions/student-faq)  \n[Python PEP8 Style Guide](https://www.python.org/dev/peps/pep-0008/)",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 796848,
          "key": "62031ed0-d82e-4c04-bf01-8430fa7957f8",
          "title": "Spark Project Workspace",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "62031ed0-d82e-4c04-bf01-8430fa7957f8",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 796851,
              "key": "f43f73bb-6bb6-4f7d-a6e6-3a2c11d0177c",
              "title": null,
              "semantic_type": "WorkspaceAtom",
              "is_public": true,
              "workspace_id": "r474340c796848xJUPYTERd00uxhei",
              "pool_id": "jupyter",
              "view_id": "jupyter-usygs",
              "gpu_capable": false,
              "configuration": {
                "id": "reserved",
                "blueprint": {
                  "conf": {
                    "disk": null,
                    "ports": [],
                    "allowGrade": false,
                    "allowSubmit": false,
                    "defaultPath": "/notebooks/Sparkify.ipynb"
                  },
                  "kind": "jupyter"
                },
                "workspaceId": "reserved"
              },
              "starter_files": null
            }
          ]
        }
      ]
    }
  }
}