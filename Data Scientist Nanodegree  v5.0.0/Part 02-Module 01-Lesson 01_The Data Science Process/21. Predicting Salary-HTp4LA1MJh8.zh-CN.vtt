WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:01.695
对于最后两个问题

00:00:01.695 --> 00:00:04.338
哪些特征与工资和工作满意度相关

00:00:04.338 --> 00:00:06.030
哪些特征与工资和工作满意度相关

00:00:06.030 --> 00:00:10.440
这两个问题 不仅是建立某种类型的预测模型

00:00:10.439 --> 00:00:15.765
还包括找到对模型影响因素的解释

00:00:15.765 --> 00:00:17.550
先导入必要的库

00:00:17.550 --> 00:00:20.894
然后观察一下感兴趣的一些列

00:00:20.894 --> 00:00:22.522
这里是我们导入的库

00:00:22.522 --> 00:00:26.114
你应该能够注意到 我们一直都在用的 NumPy 和 Pandas

00:00:26.114 --> 00:00:29.369
然后还有两个专门绘制可视化的库

00:00:29.370 --> 00:00:32.895
Matplotlib 和 seaborn

00:00:32.895 --> 00:00:36.150
后面还有 %matplotlib inline 来确保

00:00:36.149 --> 00:00:39.494
绘制图表展示在 Notebook 里面

00:00:39.494 --> 00:00:44.489
这里的三行代码其实都跟构建预测模型相关

00:00:44.490 --> 00:00:46.469
这个 train_test_split

00:00:46.469 --> 00:00:50.700
会将我们的数据集划分为训练集和测试集

00:00:50.700 --> 00:00:55.005
确保训练集上建立的模型 可以很好地扩展到测试集

00:00:55.005 --> 00:00:56.609
这里的指标部分

00:00:56.609 --> 00:00:59.804
可以与任何类型的连续型目标变量

00:00:59.804 --> 00:01:04.515
一起使用的非常常见的指标 R 平方值和均方误差

00:01:04.515 --> 00:01:08.430
在这里 我只是使用了简单的线性回归模型

00:01:08.430 --> 00:01:12.960
其实有很多其他的模型可以用来训练数据

00:01:12.959 --> 00:01:15.869
取决于对机器学习的了解程度

00:01:15.870 --> 00:01:17.490
你可能对这里的内容非常熟悉

00:01:17.489 --> 00:01:19.920
我们在后续课程中还会继续深入 讲解相关的工作原理

00:01:19.920 --> 00:01:23.939
我们在后续课程中还会继续深入 讲解相关的工作原理

00:01:23.939 --> 00:01:25.769
在这里读入数据

00:01:25.769 --> 00:01:28.769
快速地浏览一下前五行数据

00:01:28.769 --> 00:01:32.655
在前面的视频中 你也已经看到过很多次这样的操作了

00:01:32.655 --> 00:01:39.810
我们也可以浏览一下连续型数值变量的情况

00:01:39.810 --> 00:01:43.350
这里看到的就是数据中的连续变量了

00:01:43.349 --> 00:01:49.369
里面的值主要是一些统计变量 比如最大值、第三四分位数、中位数、

00:01:49.370 --> 00:01:52.280
第一四分位数、最小值、标准差、均值等

00:01:52.280 --> 00:01:53.870
这里的计数非常有用

00:01:53.870 --> 00:01:59.240
因为其可以展示每个特征缺失值的情况

00:01:59.239 --> 00:02:05.824
你可以看到 只有 12891 个人发布了自己的工资

00:02:05.825 --> 00:02:08.900
这些特征也有缺失值存在

00:02:08.900 --> 00:02:12.590
因为答卷者总数似乎在 51000 左右

00:02:12.590 --> 00:02:16.594
快速地来看一下

00:02:16.594 --> 00:02:20.229
是的 的确有 51392 个答卷者

00:02:20.229 --> 00:02:23.834
也就是说 任何一个没有这么多计数的列

00:02:23.835 --> 00:02:26.865
都包含了缺失值

00:02:26.865 --> 00:02:30.360
一种很快捷的查看这些变量的方法

00:02:30.360 --> 00:02:33.825
就是绘制直方图

00:02:33.824 --> 00:02:37.500
非常方便 我会在后面加上分号

00:02:37.500 --> 00:02:41.250
这样就不会出现多余的文字了

00:02:41.250 --> 00:02:43.664
这里你可以看到

00:02:43.664 --> 00:02:45.929
每个回答都出现了一次

00:02:45.930 --> 00:02:47.969
所以这个图表看上去很不一样

00:02:47.969 --> 00:02:49.484
不过你也可以看到

00:02:49.485 --> 00:02:51.780
工作满意度以及对 Stack Overflow 的满意度都是左偏的

00:02:51.780 --> 00:02:56.917
工作满意度以及对 Stack Overflow 的满意度都是左偏的

00:02:56.917 --> 00:02:59.460
工资是右偏的

00:02:59.460 --> 00:03:03.390
周工作时长和期望工资也是右偏的

00:03:03.389 --> 00:03:08.069
职业满意度则是左偏的

00:03:08.069 --> 00:03:10.469
看上去 这些人对自己工作和职业都是比较满意的

00:03:10.469 --> 00:03:15.359
而且不怎么过度加班

00:03:15.360 --> 00:03:17.430
这是一种观察数据的方式

00:03:17.430 --> 00:03:20.430
另一种我自己经常在分析前期用的图表

00:03:20.430 --> 00:03:23.625
就是热图

00:03:23.625 --> 00:03:25.680
我们来看一下

00:03:25.680 --> 00:03:28.875
这里的 sns 就是指 seaborn 库

00:03:28.875 --> 00:03:30.930
其中有内置的热图函数

00:03:30.930 --> 00:03:33.810
如果你传入一个相关系数矩阵

00:03:33.810 --> 00:03:38.564
其实就可以画出图表了

00:03:38.564 --> 00:03:41.159
但是 我要再传入标签

00:03:41.159 --> 00:03:43.740
以及要求的小数位数

00:03:43.740 --> 00:03:52.020
也就是让相关系数都保留两位小数

00:03:52.020 --> 00:03:59.070
然后在代码后面加上一个分号

00:03:59.069 --> 00:04:00.884
这样就不会返回第一行的文字

00:04:00.884 --> 00:04:03.284
这会绘制出 显示数据中所有数值变量之间相关系数的矩阵

00:04:03.284 --> 00:04:05.729
这会绘制出 显示数据中所有数值变量之间相关系数的矩阵

00:04:05.729 --> 00:04:08.504
然后我还会做的事情是

00:04:08.504 --> 00:04:12.509
创建一个 DataFrame 其中包含所有用来预测目标变量的特征

00:04:12.509 --> 00:04:17.108
创建一个 DataFrame 其中包含所有用来预测目标变量的特征

00:04:17.108 --> 00:04:21.975
然后单独提取出需要进行预测的变量

00:04:21.975 --> 00:04:23.205
在这里 就是 Salary 列

00:04:23.204 --> 00:04:24.824
在这里 就是 Salary 列

00:04:24.824 --> 00:04:27.735
因为我们要预测的就是工资

00:04:27.735 --> 00:04:31.980
然后把所有用来预测目标变量的特征放在这个列表里

00:04:31.980 --> 00:04:34.020
我们可以放入上面看到的所有数值变量

00:04:34.019 --> 00:04:37.889
我们可以放入上面看到的所有数值变量

00:04:37.889 --> 00:04:41.019
比如职业满意度

00:04:41.019 --> 00:04:42.134
但是不用传入答卷者编号

00:04:42.134 --> 00:04:44.355
但是不用传入答卷者编号

00:04:44.355 --> 00:04:47.375
因为这对分析没有意义

00:04:47.375 --> 00:04:55.490
然后是 工作满意度、周工作时长、对 Stack Overflow 的满意度

00:04:55.490 --> 00:04:59.435
scikit-learn 内置模型中也是如此

00:04:59.435 --> 00:05:02.089
默认情况下你还可以传入截距

00:05:02.089 --> 00:05:05.145
所以并不需要将其存入 X 矩阵

00:05:05.146 --> 00:05:07.790
这只是一个参数 可以传入到任何 scikit-learn 的模型中

00:05:07.790 --> 00:05:10.865
这只是一个参数 可以传入到任何 scikit-learn 的模型中

00:05:10.865 --> 00:05:12.800
我不会为此担心

00:05:12.800 --> 00:05:16.879
接下来 我要做的是把数据分成训练集和测试集

00:05:16.879 --> 00:05:21.194
接下来 我要做的是把数据分成训练集和测试集

00:05:21.194 --> 00:05:23.589
代码是这样写的

00:05:23.589 --> 00:05:26.319
我自己经常需要查看文档才能确定正确的写法

00:05:26.319 --> 00:05:31.569
基本上就是用上面导入的 train_test_split

00:05:31.569 --> 00:05:37.704
传入 X 矩阵和目标向量

00:05:37.704 --> 00:05:43.659
然后传入一个 test_size 控制测试集占比

00:05:43.660 --> 00:05:46.780
很多时候还可以传入 random_state 随机种子

00:05:46.779 --> 00:05:52.334
我们使用随机种子 42 这是很常见的选择

00:05:52.334 --> 00:05:54.169
可以看到

00:05:54.170 --> 00:05:57.110
这个函数需要传入这个 X 矩阵

00:05:57.110 --> 00:06:00.830
也就是刚才创建的 包含了所有的预测变量

00:06:00.829 --> 00:06:03.079
还传入了这里创建的目标变量

00:06:03.079 --> 00:06:06.439
函数会将这些数据划分为两个单独的数据集

00:06:06.439 --> 00:06:08.600
使用随机方式划分 X

00:06:08.600 --> 00:06:11.990
部分划分到 X_train 部分划分到 X_test

00:06:11.990 --> 00:06:13.730
使用随机方式划分 y

00:06:13.730 --> 00:06:18.875
部分划分到 y_train 部分划分到 y_test

00:06:18.875 --> 00:06:23.720
但是划分到 y_test 和划分到 X_test 的数据是相对应的

00:06:23.720 --> 00:06:25.640
划分到 y_train 和划分到 X_train 的数据也是相对应的

00:06:25.639 --> 00:06:29.055
划分到 y_train 和划分到 X_train 的数据也是相对应的

00:06:29.055 --> 00:06:32.290
这个参数的意思是 我们想要的

00:06:32.290 --> 00:06:36.955
测试集大小是原始数据集的 30%

00:06:36.954 --> 00:06:40.269
设置随机种子也很有必要

00:06:40.269 --> 00:06:43.817
如果你想要分享代码和数据给其他人

00:06:43.817 --> 00:06:48.490
会想要他们也能使用和你一样的数据划分

00:06:48.490 --> 00:06:50.379
如果没有设置随机种子

00:06:50.379 --> 00:06:53.199
那么他们得到的训练集和测试集

00:06:53.199 --> 00:06:56.740
都会与你不同

00:06:56.740 --> 00:06:59.139
接下来我们需要做的

00:06:59.139 --> 00:07:01.952
是实例化线性回归模型

00:07:01.952 --> 00:07:06.794
拟合任何监督学习模型的第一步都是实例化模型

00:07:06.795 --> 00:07:10.395
所以首先来实例化模型

00:07:10.394 --> 00:07:14.430
接着用该模型拟合训练数据

00:07:14.430 --> 00:07:18.329
再用一些测试数据做预测

00:07:18.329 --> 00:07:24.524
最后通常需要对模型作出评分

00:07:24.524 --> 00:07:27.149
也就是 将预测结果和测试集中已知的实际结果做对比

00:07:27.149 --> 00:07:30.284
也就是 将预测结果和测试集中已知的实际结果做对比

00:07:30.285 --> 00:07:31.695
最终得到的评分

00:07:31.694 --> 00:07:36.939
能够帮助你在不同模型之间进行比较

00:07:36.939 --> 00:07:40.730
这大概就是我通常构建模型的流程

00:07:40.730 --> 00:07:42.215
第一件事是实例化模型

00:07:42.214 --> 00:07:44.989
这里就是实例化我的线性模型

00:07:44.990 --> 00:07:50.165
就像你之前看到过的方式完成操作

00:07:50.165 --> 00:07:51.965
另一个很重要的事情

00:07:51.964 --> 00:07:55.339
建模的时候

00:07:55.339 --> 00:07:59.539
通常都需要以某种方式对数据进行标准化

00:07:59.540 --> 00:08:03.170
不管是建立神经网络模型

00:08:03.170 --> 00:08:08.525
或是监督学习模型 以及很多的非监督学习模型

00:08:08.524 --> 00:08:11.929
你都需要标准化你的数据

00:08:11.930 --> 00:08:14.937
尤其是线性模型

00:08:14.937 --> 00:08:16.235
唯一的缺点就是

00:08:16.235 --> 00:08:21.754
这会使特征变得没那么容易解读

00:08:21.754 --> 00:08:26.060
但是我认为解读数据集差异的重要性

00:08:26.060 --> 00:08:29.014
其实要远远高于

00:08:29.014 --> 00:08:32.480
对数据特征的解读

00:08:32.480 --> 00:08:34.789
接下来要开始拟合模型了

00:08:34.789 --> 00:08:36.949
就是这样做

00:08:36.950 --> 00:08:38.629
我们可以先来看一下

00:08:38.629 --> 00:08:40.460
X 的前 5 行数据

00:08:40.460 --> 00:08:46.460
可以看到数据集已经被拆分过了 只有指定的那些列

00:08:46.460 --> 00:08:52.934
包含了所有指定的列 如果我们看一下 X_train

00:08:52.933 --> 00:08:59.250
你会发现前面几行的索引与之前不同 看一下 X_test

00:08:59.250 --> 00:09:01.304
也是完全不一样的

00:09:01.304 --> 00:09:04.319
如果来看一下这几个数据集的 shape

00:09:04.320 --> 00:09:09.518
可以看到测试集中有 15418 行

00:09:09.518 --> 00:09:11.550
再来看一下训练集

00:09:11.549 --> 00:09:16.740
有 35974 行

00:09:16.740 --> 00:09:22.169
训练集比测试集大很多 对于 y_train 和 y_test 也是一样

00:09:22.169 --> 00:09:24.784
我们来试一下

00:09:24.784 --> 00:09:31.219
可以看到 y_train 的样本数跟 X_train 是一样的 只不过它只有一列

00:09:31.220 --> 00:09:36.620
再来看下 y_test

00:09:36.620 --> 00:09:38.975
它也只有一列

00:09:38.975 --> 00:09:42.245
索引都是相匹配的 y_train 与 X_train、y_test 与 X_test

00:09:42.245 --> 00:09:44.715
好了 完成这一步

00:09:44.715 --> 00:09:46.820
可以开始拟合模型了

00:09:46.820 --> 00:09:49.520
用我们的训练数据

00:09:49.519 --> 00:09:55.504
传入 X_train 和 y_train

00:09:55.504 --> 00:09:58.654
搞定 就是这样的顺序

00:09:58.654 --> 00:10:00.809
不过我们也可以再来看一下文档

00:10:00.809 --> 00:10:03.389
我通常会对照自己以前写过的代码

00:10:03.389 --> 00:10:06.794
或者查看 scikit-learn 文档

00:10:06.794 --> 00:10:10.439
你也可以直接在函数后面打个问号查看文档

00:10:10.440 --> 00:10:14.640
就是这样 lm_model.fit 函数需要传入参数 X 和 y

00:10:14.639 --> 00:10:16.199
然后还有这个 sample_weight

00:10:16.200 --> 00:10:18.000
接下来就是每个参数的具体说明

00:10:18.000 --> 00:10:19.649
很有帮助

00:10:19.649 --> 00:10:23.250
运行代码出现了报错

00:10:23.250 --> 00:10:26.399
不过这节课就先讲到这里

00:10:26.399 --> 00:10:30.855
你应该自己过一遍这些步骤

00:10:30.855 --> 00:10:33.670
然后看你的代码中会发生什么

