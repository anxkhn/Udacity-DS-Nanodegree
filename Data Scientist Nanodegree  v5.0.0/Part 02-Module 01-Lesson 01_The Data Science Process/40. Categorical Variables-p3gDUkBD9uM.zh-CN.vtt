WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:01.635
在前面的视频中

00:00:01.635 --> 00:00:05.250
我们做了一些处理缺失值的练习

00:00:05.250 --> 00:00:09.884
使用删除或填充的方式

00:00:09.884 --> 00:00:15.300
如果选择填充缺失值 我们可以对所有样本作出预测

00:00:15.300 --> 00:00:19.320
但是 我们仍然没有充分利用分类变量

00:00:19.320 --> 00:00:20.940
所以 在这个视频中

00:00:20.940 --> 00:00:23.730
我们会了解如何利用分类变量

00:00:23.730 --> 00:00:26.565
主要方法就是使用 0/1 编码 (也称独热编码)

00:00:26.565 --> 00:00:31.710
这种方法具备一些优势 使其比较受欢迎

00:00:31.710 --> 00:00:35.700
但它也存在可扩展性的问题

00:00:35.700 --> 00:00:40.560
你会在本次 Notebook 某些代码运行的时候看到

00:00:40.560 --> 00:00:44.887
当有很多分类变量的时候 比如当前数据集

00:00:44.887 --> 00:00:49.575
就会导致可扩展性的问题 这也是独热编码的劣势

00:00:49.575 --> 00:00:52.370
在这个 Notebook 中就可以看到

00:00:52.369 --> 00:00:56.074
对于可扩展性问题 其实有其他的应对办法

00:00:56.075 --> 00:00:58.115
在 Notebook 的第一部分

00:00:58.115 --> 00:00:59.990
我们只是在重复

00:00:59.990 --> 00:01:02.210
之前视频里走过的步骤

00:01:02.210 --> 00:01:03.670
读取数据

00:01:03.670 --> 00:01:05.424
选择数值型变量

00:01:05.424 --> 00:01:08.855
删除 Salary 存在缺失值的数据

00:01:08.855 --> 00:01:14.510
用均值填充其他列的缺失数据

00:01:14.510 --> 00:01:17.930
用均值填充其他列的缺失数据

00:01:17.930 --> 00:01:19.910
将数据划分为 X 和 y

00:01:19.909 --> 00:01:22.459
拆分训练集和测试集

00:01:22.459 --> 00:01:25.774
然后评估模型的表现

00:01:25.775 --> 00:01:27.870
在这里可以看到结果

00:01:27.870 --> 00:01:30.460
在 Notebook 剩下的内容中

00:01:30.459 --> 00:01:32.619
我们主要是想看看 使用分类变量

00:01:32.620 --> 00:01:35.380
会不会提升模型的表现

00:01:35.379 --> 00:01:37.765
第一个问题

00:01:37.765 --> 00:01:42.594
找出 df 数据中的分类变量

00:01:42.594 --> 00:01:47.155
提取出只包含分类变量的数据部分

00:01:47.155 --> 00:01:51.474
这里还给了一个文档链接 打开看一下

00:01:51.474 --> 00:01:53.875
打开的页面中 这里的内容比较有用

00:01:53.875 --> 00:01:55.299
打开的页面中 这里的内容比较有用

00:01:55.299 --> 00:02:00.006
你可以使用 select_dtypes 来筛选出特定数据类型的列

00:02:00.007 --> 00:02:02.260
基本上只需要传入类型名称

00:02:02.260 --> 00:02:06.615
比如 int float object bool 等

00:02:06.614 --> 00:02:08.370
所有你可以看到的数据类型

00:02:08.370 --> 00:02:10.289
都可以传入到 include 参数中

00:02:10.289 --> 00:02:13.875
该函数就会返回数据子集 其中只包含指定数据类型的列

00:02:13.875 --> 00:02:22.710
好的 使用 select_dtypes 设定 include 参数

00:02:22.710 --> 00:02:26.370
传入的是一个列表 我们只需要 object 类型

00:02:26.370 --> 00:02:29.355
然后将结果存在 cat_df 里面

00:02:29.354 --> 00:02:34.049
这里显示 有 147 列是分类变量

00:02:34.050 --> 00:02:35.805
打印数据看一下

00:02:35.805 --> 00:02:39.486
可以看到这些列都是分类变量

00:02:39.486 --> 00:02:43.139
如果再来看原数据集

00:02:43.139 --> 00:02:46.154
可以看到 respondent 在 cat_df 中被删除了

00:02:46.155 --> 00:02:52.349
后面的工资和预期工资两列也被删除了

00:02:52.349 --> 00:02:54.479
检查答案

00:02:54.479 --> 00:02:56.969
回答正确

00:02:56.969 --> 00:02:58.509
接下来的问题是

00:02:58.509 --> 00:03:00.780
使用 cat_df 回答 cat_df_dict 字典中的问题

00:03:00.780 --> 00:03:03.645
在字典对应位置 填写正确的数字

00:03:03.645 --> 00:03:05.322
第一个问题是

00:03:05.322 --> 00:03:08.028
不存在缺失值的列数是多少?

00:03:08.028 --> 00:03:11.099
使用 cat_df 我们想要了解的是

00:03:11.099 --> 00:03:14.643
不存在缺失值的列数是多少?

00:03:14.643 --> 00:03:18.215
先使用 isnull()

00:03:18.215 --> 00:03:20.750
会得到很多 True 和 False

00:03:20.750 --> 00:03:22.550
对这些值进行求和

00:03:22.550 --> 00:03:25.775
也就是使用 np.sum

00:03:25.775 --> 00:03:28.564
得到了一些 0 值和其他数字

00:03:28.564 --> 00:03:31.219
这个结果其实就是每一列包含的缺失值数量

00:03:31.219 --> 00:03:33.020
可以看到有一些列的值是 0

00:03:33.020 --> 00:03:36.125
我们可以用这种方式提取所有等于 0 的列

00:03:36.125 --> 00:03:37.444
我们可以用这种方式提取所有等于 0 的列

00:03:37.444 --> 00:03:38.810
又得到了一些 True 和 False

00:03:38.810 --> 00:03:40.909
再次使用 sum

00:03:40.909 --> 00:03:43.085
这就是最终结果了

00:03:43.085 --> 00:03:44.300
接下来的问题

00:03:44.300 --> 00:03:47.855
缺失值占比一半以上的列数

00:03:47.854 --> 00:03:53.514
使用跟之前非常相似的方法

00:03:53.514 --> 00:03:58.479
不过需要注意 这里的是计数

00:03:58.479 --> 00:04:01.405
如果想要比例的话

00:04:01.405 --> 00:04:04.599
需要将其除以数据行数

00:04:04.599 --> 00:04:09.414
数据行数可以由 shape 的第一个元素得到

00:04:09.414 --> 00:04:11.889
这个就是数据行数了

00:04:11.889 --> 00:04:14.064
如果让缺失值数量除以数据总量

00:04:14.064 --> 00:04:17.274
如果让缺失值数量除以数据总量

00:04:17.274 --> 00:04:19.929
就能得到缺失值的比例

00:04:19.930 --> 00:04:23.275
这里就是每个特征包含的缺失值比例

00:04:23.274 --> 00:04:31.764
然后 我们可以判断其是否大于 0.5

00:04:31.764 --> 00:04:34.300
会得到一些 True 和 False

00:04:34.300 --> 00:04:37.509
会得到一些 True 和 False

00:04:37.509 --> 00:04:41.409
再次取 sum 得到结果是 49

00:04:41.410 --> 00:04:47.605
也就是说 有 49 列的缺失值比例是大于 50% 的

00:04:47.605 --> 00:04:51.009
最后一个是 超过 75% 缺失值的列数

00:04:51.009 --> 00:04:53.709
这个很好办 就是修改下数字

00:04:53.709 --> 00:04:56.364
结果是 13

00:04:56.365 --> 00:04:58.780
其实可以用任何的值来比较

00:04:58.779 --> 00:05:00.309
比如说 80%

00:05:00.310 --> 00:05:01.795
或者是 90%

00:05:01.795 --> 00:05:03.490
或者 5%

00:05:03.490 --> 00:05:05.110
在最后的部分

00:05:05.110 --> 00:05:08.004
我们使用 dummy_var_df 数据集

00:05:08.004 --> 00:05:11.139
其中有两列

00:05:11.139 --> 00:05:14.079
有一列只有 a 和 b 两种值

00:05:14.079 --> 00:05:15.534
另一个是数值型的

00:05:15.535 --> 00:05:19.540
我用这个单元格 为 col1 创建虚拟变量

00:05:19.540 --> 00:05:22.780
我们想做的是为所有的分类变量创建虚拟变量

00:05:22.779 --> 00:05:26.106
我们想做的是为所有的分类变量创建虚拟变量

00:05:26.107 --> 00:05:30.700
在这里 就是 col1 列 而对于这个数值型变量 则不需要虚拟编码

00:05:30.699 --> 00:05:35.620
很多时候 我们可以为其创建虚拟变量 只用来识别是否缺失

00:05:35.620 --> 00:05:39.519
也许以后可以想出另一种方法来实际使用这些数字

00:05:39.519 --> 00:05:43.884
以及是否含有缺失值的信息

00:05:43.884 --> 00:05:46.539
第一个问题是

00:05:46.540 --> 00:05:48.745
我们需要对哪一列创建虚拟变量?

00:05:48.745 --> 00:05:51.355
应该是 col1 也就是 d

00:05:51.355 --> 00:05:54.980
如果使用默认设置创建虚拟变量

00:05:54.980 --> 00:05:56.360
会创建多少列?

00:05:56.360 --> 00:06:02.675
如果使用创建默认设置创建虚拟变量 会创建多少列?

00:06:02.675 --> 00:06:05.000
如果运行这行代码

00:06:05.000 --> 00:06:08.345
该函数会为我们创建虚拟变量

00:06:08.345 --> 00:06:11.120
我们传入一个列

00:06:11.120 --> 00:06:14.180
它会为这个列创建虚拟变量

00:06:14.180 --> 00:06:16.189
使用 0 或 1 进行编码

00:06:16.189 --> 00:06:21.069
在这个示例中 创建了 2 列

00:06:21.069 --> 00:06:23.490
下一个问题 缺失值是如何处理的?

00:06:23.490 --> 00:06:25.620
回到这里

00:06:25.620 --> 00:06:31.680
索引 5 和 7 的地方其实是有缺失值的

00:06:31.680 --> 00:06:33.555
看一下这两行数据

00:06:33.555 --> 00:06:35.894
它们的值都是 0

00:06:35.894 --> 00:06:41.412
该函数不会删除缺失值

00:06:41.413 --> 00:06:45.074
而是将缺失值编码为 0

00:06:45.074 --> 00:06:47.639
好的 下一个问题

00:06:47.639 --> 00:06:51.180
注意 get_dummies 可以对 NaN 值进行编码

00:06:51.180 --> 00:06:53.759
其中有一个 dummy_na 参数

00:06:53.759 --> 00:06:58.740
你可以使用 dummy_na 参数 传入一个布尔值

00:06:58.740 --> 00:07:00.225
我们来看一下官方文档

00:07:00.225 --> 00:07:02.340
我们来看一下官方文档

00:07:02.339 --> 00:07:04.469
dummy_na 参数是布尔值

00:07:04.470 --> 00:07:06.765
默认值是 False

00:07:06.764 --> 00:07:08.474
当设置为 False 时

00:07:08.475 --> 00:07:10.935
就会忽略 NaN 值

00:07:10.935 --> 00:07:12.540
也就是将其编码为 0

00:07:12.540 --> 00:07:14.025
如果设置为 True

00:07:14.024 --> 00:07:19.424
就会增加一列虚拟变量 标识是否缺失数据

00:07:19.425 --> 00:07:23.009
我们来看一下能不能用

00:07:23.009 --> 00:07:27.884
传入第一列数据 col1

00:07:27.884 --> 00:07:29.805
传入了第一列

00:07:29.805 --> 00:07:36.487
然后把 dummy_na 设为 True

00:07:36.487 --> 00:07:40.870
这句代码的作用是 将缺失值表示出来

00:07:40.870 --> 00:07:46.285
于是 这里就能看到一个新列 nan

00:07:46.285 --> 00:07:48.685
这里有一个 1

00:07:48.685 --> 00:07:51.235
而之前 只是在这两个地方看到两个 0

00:07:51.235 --> 00:07:54.355
我们可以检查下答案

00:07:54.355 --> 00:07:58.134
回答正确! 在最后一部分

00:07:58.134 --> 00:08:01.569
我们想做的是

00:08:01.569 --> 00:08:06.879
创建一个处理了所有分类变量的数据集

00:08:06.879 --> 00:08:09.069
也就是说

00:08:09.069 --> 00:08:14.240
我们要将这个流程应用于数据集的每个分类变量

00:08:14.240 --> 00:08:17.810
然后创建一个新的数据集

00:08:17.810 --> 00:08:21.964
其中包含所有分类变量的虚拟变量

00:08:21.964 --> 00:08:24.439
题目要求 新的数据集应该包含所有列 不仅仅是分类特征

00:08:24.439 --> 00:08:28.100
题目要求 新的数据集应该包含所有列 不仅仅是分类特征

00:08:28.100 --> 00:08:30.455
也就是说 如果数据类型为 float、int

00:08:30.454 --> 00:08:33.995
或其他任何类型 都应该包含在我们的数据集中

00:08:33.995 --> 00:08:36.995
其中移除了所有原始的数据列

00:08:36.995 --> 00:08:41.404
也就是说 有了虚拟变量 就不再需要原来的分类变量了

00:08:41.404 --> 00:08:46.528
然后 每个分类变量的虚拟变量都应该包含在该数据集中

00:08:46.528 --> 00:08:51.210
如果 dummy_na 设为 True 还需要包含额外的列

00:08:51.210 --> 00:08:54.344
可以看到 这里的参数是 df

00:08:54.344 --> 00:08:59.055
分类类型的列 以及是否要处理缺失值

00:08:59.054 --> 00:09:05.354
这里有一行非常复杂的代码 看似可以完成任务

00:09:05.355 --> 00:09:10.259
其中实际上就是使用了 concat 函数

00:09:10.259 --> 00:09:16.169
把分类变量和非分类变量拼接到一起

00:09:16.169 --> 00:09:22.860
这里还应该要加一个 for col in cat_cols

00:09:22.860 --> 00:09:26.610
对于 cat_cols 中的每一列

00:09:26.610 --> 00:09:31.154
进入循环 删除原始列

00:09:31.154 --> 00:09:35.220
drop 设置 axis=1 也就是删除列

00:09:35.220 --> 00:09:37.004
对这一列创建虚拟变量

00:09:37.004 --> 00:09:39.509
这一部分

00:09:39.509 --> 00:09:43.139
就是虚拟变量的具体设定

00:09:43.139 --> 00:09:45.330
删除第一列

00:09:45.330 --> 00:09:48.120
dummy_na 这个变量可以指定为 True 或者 False

00:09:48.120 --> 00:09:51.350
是这个函数的输入值

00:09:51.350 --> 00:09:56.634
然后我还设置了 prefix_sep 不过你也可以不设置

00:09:56.634 --> 00:10:02.889
该参数是设置列名前缀的分隔符

00:10:02.889 --> 00:10:08.394
后面的 axis 等于 1 其实是属于 concat 函数

00:10:08.394 --> 00:10:11.245
再理解一次 对每一个分类变量

00:10:11.245 --> 00:10:14.049
进入循环 删掉这一列

00:10:14.049 --> 00:10:15.954
为其创建虚拟变量

00:10:15.955 --> 00:10:21.280
最后再把虚拟变量和之前的数据集拼在一起

00:10:21.279 --> 00:10:23.934
将其保存在 df 中

00:10:23.934 --> 00:10:27.250
再继续循环

00:10:27.250 --> 00:10:31.639
现在 我们可以用这个函数 为分类变量创建新的 DataFrame 了

00:10:31.639 --> 00:10:37.189
确保再检查一下 shape 符合预期

00:10:37.190 --> 00:10:39.650
接下来 是一个很长的函数

00:10:39.649 --> 00:10:41.299
不过好消息是

00:10:41.299 --> 00:10:46.564
你需要做的大部分其实主要是前面做过的内容

00:10:46.565 --> 00:10:48.770
基本上用之前完成的部分

00:10:48.769 --> 00:10:51.470
就能完成最后的任务了

