WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:01.725
在这个 Notebook 里

00:00:01.725 --> 00:00:03.089
我们将对课程使用的数据有个更好的理解

00:00:03.089 --> 00:00:06.134
我们将对课程使用的数据有个更好的理解

00:00:06.134 --> 00:00:14.214
有几点小提示 点击这里的 Jupyter 图标

00:00:14.214 --> 00:00:17.280
你会看到一个文件列表 其中包括

00:00:17.280 --> 00:00:21.095
本节课程用到的所有练习及其解决方案

00:00:21.094 --> 00:00:23.294
如果选择下载所有文件

00:00:23.295 --> 00:00:25.215
在本地计算机上运行

00:00:25.214 --> 00:00:27.000
你也可以参考教室 Workspace 的顺序完成对应练习

00:00:27.000 --> 00:00:30.629
你也可以参考教室 Workspace 的顺序完成对应练习

00:00:30.629 --> 00:00:32.299
按自己的喜好决定如何操作

00:00:32.299 --> 00:00:33.719
你会注意到

00:00:33.719 --> 00:00:36.149
这里有一个 Notebook 练习 这里就是其对应的解决方案

00:00:36.149 --> 00:00:37.934
这里是一个 Notebook 练习 这里就是它的解决方案

00:00:37.935 --> 00:00:40.875
Notebook 练习、解决方案 一直是这个顺序

00:00:40.875 --> 00:00:44.130
然后你还会看到有一个 solution1.py 文件

00:00:44.130 --> 00:00:45.810
还有这个 test1.py 的文件

00:00:45.810 --> 00:00:48.795
这些其实是用来检查

00:00:48.795 --> 00:00:52.410
你在每个 Notebook 中编写的解决方案是否正确

00:00:52.409 --> 00:00:56.564
回到 A Look at the Data 这个 Notebook

00:00:56.564 --> 00:00:59.964
首先是读入需要的库

00:00:59.965 --> 00:01:03.510
你会看到 这里有一行 import test1 as t

00:01:03.509 --> 00:01:08.129
其读入的就是 test1.py 这个文件

00:01:08.129 --> 00:01:11.265
然后这里 就是在读取数据

00:01:11.265 --> 00:01:13.049
并将其存储在 df 变量中

00:01:13.049 --> 00:01:17.354
一旦看到数据的前几行

00:01:17.355 --> 00:01:19.359
我们就知道代码已经被成功执行了

00:01:19.359 --> 00:01:21.194
然后就可以继续

00:01:21.194 --> 00:01:26.459
如果 Workspace 不是你运行代码的最优选择

00:01:26.459 --> 00:01:28.569
你也可以在本地计算机上运行

00:01:28.569 --> 00:01:32.429
在这里 你可以看到我们使用的数据

00:01:32.430 --> 00:01:35.100
第一个问题是

00:01:35.099 --> 00:01:37.649
给出数据的行和列

00:01:37.650 --> 00:01:39.180
如果我们运行这个单元格

00:01:39.180 --> 00:01:40.765
你会看到结果显示 Nice job 做得很好

00:01:40.765 --> 00:01:43.469
数据中有这些行 这些列

00:01:43.469 --> 00:01:46.254
可以看到这里运行了一个检测代码

00:01:46.254 --> 00:01:49.125
也就是 t.check_rows_cols

00:01:49.125 --> 00:01:51.799
传入了这样两个变量名称

00:01:51.799 --> 00:01:55.420
这里的 t 其实就是幕后的测试文件

00:01:55.420 --> 00:01:59.159
里面有一个函数叫做 check_rows_cols

00:01:59.159 --> 00:02:02.909
也就是检查这里输入的行和列

00:02:02.909 --> 00:02:07.170
跟答案中的行和列进行比较

00:02:07.170 --> 00:02:09.942
如果存在错误

00:02:09.942 --> 00:02:11.340
你会看到这样的提示

00:02:11.340 --> 00:02:12.870
这跟预期结果不一致

00:02:12.870 --> 00:02:14.789
这跟预期结果不一致

00:02:14.789 --> 00:02:17.054
可以看到这是一个行列颠倒的结果

00:02:17.055 --> 00:02:18.465
这里是 df.shape

00:02:18.465 --> 00:02:22.599
第一个元素 索引为 0 的元素是行数

00:02:22.599 --> 00:02:23.884
第二个元素

00:02:23.884 --> 00:02:26.250
索引为 1 的元素是列数

00:02:26.250 --> 00:02:28.694
如果将行列弄反了

00:02:28.694 --> 00:02:31.037
基本上就是错误的答案

00:02:31.038 --> 00:02:35.927
如果我们把这一结果跟测试里的 check_rows_cols 函数做比较

00:02:35.927 --> 00:02:40.740
它会告诉我们 回答错误

00:02:40.740 --> 00:02:46.254
另外 在每个检查答案的函数中都有文档字符串注释

00:02:46.254 --> 00:02:49.379
另外 在每个检查答案的函数中都有文档字符串注释

00:02:49.379 --> 00:02:50.669
如果你运行这行代码 (t.check_rows_cols?)

00:02:50.669 --> 00:02:53.594
会看到函数要求的输入信息

00:02:53.594 --> 00:02:55.830
其中提到 输入应该包含行的数量

00:02:55.830 --> 00:02:59.625
这个参数应该是一个 int 类型的数字 表示 DataFrame 的行数

00:02:59.625 --> 00:03:04.205
num_cols 应该是一个 int 类型的数字 表示 DataFrame 的列数

00:03:04.205 --> 00:03:07.620
测试文件里的每个函数

00:03:07.620 --> 00:03:13.250
都有自己对应的文档字符串 你可以检查其信息

00:03:13.250 --> 00:03:15.270
之后的内容

00:03:15.270 --> 00:03:18.325
需要你自己来完成

00:03:18.324 --> 00:03:23.174
问题是 给出数据中所有不含缺失值的列名集合

00:03:23.175 --> 00:03:30.460
有时你可能需要创建新的单元格 在其中编写代码

00:03:30.460 --> 00:03:33.000
我现在就在上面插入一个单元格

00:03:33.000 --> 00:03:39.080
如果输入 df.isnull()

00:03:39.080 --> 00:03:43.480
会看到很多列

00:03:43.479 --> 00:03:51.109
我们可以查看 Pandas 的 isnull 文档

00:03:51.110 --> 00:03:56.260
我想一下 是不是可以这样做

00:03:56.259 --> 00:04:00.199
加入 axis = 1

00:04:00.199 --> 00:04:02.209
不行

00:04:02.210 --> 00:04:04.338
或者 这样

00:04:04.338 --> 00:04:07.000
好的 可以 如果我们运行 np.sum

00:04:07.000 --> 00:04:12.469
如果没有缺失值 就显示为 0

00:04:12.469 --> 00:04:15.430
如果有缺失值

00:04:15.430 --> 00:04:18.459
就会给出具体的数值

00:04:18.459 --> 00:04:23.799
如果添加 == 0

00:04:23.800 --> 00:04:25.860
就可以得到很多的 True 和 False

00:04:25.860 --> 00:04:30.069
现在我直接在外面套 df.columns[]

00:04:30.069 --> 00:04:33.954
就会获得所有为 True 的列名

00:04:33.954 --> 00:04:36.219
好的 这句代码就是

00:04:36.220 --> 00:04:42.030
筛选出所有空值总数为 0 的列名

00:04:42.029 --> 00:04:44.125
但是这个问题的要求是

00:04:44.125 --> 00:04:48.334
给出所有不含缺失值的列名集合 (set)

00:04:48.334 --> 00:04:50.470
所以我们可以先复制这些代码

00:04:50.470 --> 00:04:53.690
然后将其指定为一个集合

00:04:53.689 --> 00:04:54.925
就像这样

00:04:54.925 --> 00:04:59.375
将这些代码包括在 set 的括号里

00:04:59.375 --> 00:05:01.610
好了 如果答案是正确的

00:05:01.610 --> 00:05:04.069
就会看到 (先将下面这个框关掉)

00:05:04.069 --> 00:05:07.849
很好 你的回答是正确的

00:05:07.850 --> 00:05:09.590
如果做错了

00:05:09.589 --> 00:05:14.174
比如说 我在后面加上随便一个东西 "thing"

00:05:14.175 --> 00:05:16.985
不仅不能得到正确的结果 还会报错

00:05:16.985 --> 00:05:22.069
还可以这样试一下

00:05:22.069 --> 00:05:26.079
结果显示 看上去不是无缺失值列名集合

00:05:26.079 --> 00:05:28.152
列表里应该包含 7 个列名

00:05:28.153 --> 00:05:30.390
然后 我们就可以回去这里 进行修改

00:05:30.389 --> 00:05:33.625
我们应该按照它的提示修改

00:05:33.625 --> 00:05:38.629
这个提示虽然也不完美 但你至少

00:05:38.629 --> 00:05:40.784
明白自己之前的答案是错误的

00:05:40.785 --> 00:05:43.729
然后返回去修改代码

00:05:43.728 --> 00:05:48.014
好的 第三个问题问 哪一列缺失值最多?

00:05:48.014 --> 00:05:50.449
给出那些具有 75% 以上缺失值的列

00:05:50.449 --> 00:05:53.629
给出那些具有 75% 以上缺失值的列

00:05:53.629 --> 00:05:58.889
我们其实可以重新利用这里的代码

00:05:58.889 --> 00:06:01.169
让我们先把这个注释掉

00:06:01.170 --> 00:06:04.016
然后我把这里改回 0

00:06:04.016 --> 00:06:07.935
哦 这个其实没关系

00:06:07.935 --> 00:06:15.269
我们可以看到这里的输出

00:06:15.269 --> 00:06:22.969
如果将其除以 df.shape[0] 就可以得到很多小数

00:06:22.970 --> 00:06:27.860
然后与 0.75 做比较

00:06:27.860 --> 00:06:29.970
这样就可以得到

00:06:29.970 --> 00:06:32.310
很多缺失值比例大于 0.75 的列

00:06:32.310 --> 00:06:35.800
接下来 我们可以从中提取 True 的列

00:06:35.800 --> 00:06:40.574
这里的意思就是 算出所有列的缺失值

00:06:40.574 --> 00:06:42.964
除以数据的总量

00:06:42.964 --> 00:06:45.022
如果结果大于 0.75

00:06:45.023 --> 00:06:46.671
就会返回列的名称

00:06:46.670 --> 00:06:49.360
我觉得这个答案是正确的

00:06:49.360 --> 00:06:53.555
把这个注释掉

00:06:53.555 --> 00:06:57.965
然后还需要套一个 set

00:06:57.964 --> 00:07:00.469
好的 下一题是

00:07:00.470 --> 00:07:04.310
给出表示每个职业人数的 Pandas Series

00:07:04.310 --> 00:07:13.714
我们可以对 professional 列使用 value_counts 函数

00:07:13.714 --> 00:07:17.424
该函数对于所有分类变量都很有用

00:07:17.425 --> 00:07:24.275
基本上 如果这一列是分类变量

00:07:24.274 --> 00:07:26.884
用 value_counts 就可以得到每个类别的数量

00:07:26.884 --> 00:07:30.519
并且结果是一个 Pandas Series

00:07:30.519 --> 00:07:34.129
来运行一下

00:07:34.129 --> 00:07:39.103
可以看到数据中 有 13000 名职业开发者、2800 名学生

00:07:39.103 --> 00:07:44.180
如果运行这个单元格

00:07:44.180 --> 00:07:46.139
应该可以看到一个柱状图

00:07:46.139 --> 00:07:48.199
代表了开发者类型的分布

00:07:48.199 --> 00:07:51.050
我们来仔细看一下柱状图

00:07:51.050 --> 00:07:54.199
其中显示有 70% 是在职的开发者

00:07:54.199 --> 00:07:57.507
15% 是学生

00:07:57.507 --> 00:08:00.305
这个问题是 给出每个 FormalEducation 类别数量的 Pandas Series

00:08:00.305 --> 00:08:03.949
跟之前做的非常像

00:08:03.949 --> 00:08:10.314
对 "FormalEducation" 列使用 value_counts

00:08:10.314 --> 00:08:16.084
之后再运行这个单元格 就又可以看到柱状图

00:08:16.084 --> 00:08:19.581
最后一个问题是针对国家的信息

00:08:19.581 --> 00:08:25.625
同样地 df['Country']

00:08:25.625 --> 00:08:29.345
然后是 value_counts

00:08:29.345 --> 00:08:31.430
返回了排名前 10 的结果

00:08:31.430 --> 00:08:36.615
在这里你可以看到 这是调查参与者最多的 10 个国家

00:08:36.615 --> 00:08:39.889
这里提示 你可以继续这样来探索数据

00:08:39.889 --> 00:08:43.000
用同样的方式来探索自己感兴趣的列

