WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.815
在这个视频中 我们将综合运用前面学习的内容

00:00:04.815 --> 00:00:06.419
首先

00:00:06.419 --> 00:00:10.509
还是照样导入需要的库和数据

00:00:10.509 --> 00:00:16.429
我会跳过一些问题的讲解 比如这里只是填充对应的文字

00:00:16.429 --> 00:00:18.870
主要讲解大家在之前视频里 没有见过的内容

00:00:18.870 --> 00:00:22.109
主要讲解大家在之前视频里 没有见过的内容

00:00:22.109 --> 00:00:28.074
这里 你要根据这些步骤编写一个函数

00:00:28.074 --> 00:00:32.539
首先 将 Salary 列存在缺失值的数据删除

00:00:32.539 --> 00:00:36.427
拆分出目标变量

00:00:36.427 --> 00:00:43.619
然后删除一些变量 构建 X 矩阵

00:00:43.619 --> 00:00:47.034
筛选出数值型变量 用均值填充缺失值

00:00:47.034 --> 00:00:49.259
很多之前做过的操作

00:00:49.259 --> 00:00:52.009
比如 用均值填充缺失值

00:00:52.009 --> 00:00:54.369
这一部分 你创建了虚拟变量

00:00:54.369 --> 00:00:56.534
同样也在之前做过

00:00:56.534 --> 00:00:59.279
然后就得到了整洁的 X 矩阵 和 y 向量

00:00:59.280 --> 00:01:04.150
然后就得到了整洁的 X 矩阵 和 y 向量

00:01:04.150 --> 00:01:07.260
这部分最后的内容就是看一下

00:01:07.260 --> 00:01:12.405
不同截断情况的 X 和 y 对应的线性模型表现如何

00:01:12.405 --> 00:01:16.620
你也许注意到了 这里其实是调用了一个函数

00:01:16.620 --> 00:01:21.359
我们可以到定义函数的文件里看一下

00:01:21.359 --> 00:01:25.709
你可以看到刚才调用的 fine_optimal_lm 函数

00:01:25.709 --> 00:01:29.414
这些是函数的输入值

00:01:29.415 --> 00:01:31.080
这里的代码

00:01:31.079 --> 00:01:33.390
其实就是创建了一些空的列表、字典等

00:01:33.390 --> 00:01:35.768
供整个函数使用

00:01:35.768 --> 00:01:38.144
这里是遍历所有的截断点

00:01:38.144 --> 00:01:44.219
截断点就是指允许某一列存在缺失值 (非 0 值) 的数量

00:01:44.219 --> 00:01:49.935
截断点值越小 X 里包含的特征数就越多

00:01:49.935 --> 00:01:56.045
截断点值越大 X 里的特征数就越少

00:01:56.045 --> 00:01:59.370
这里可以看到对截断点的应用

00:01:59.370 --> 00:02:02.840
你在根据截断点减小 X 的大小

00:02:02.840 --> 00:02:05.635
这个 X.sum 并不是缺失值的数量

00:02:05.635 --> 00:02:07.675
而是 列中数据为 1 的总数

00:02:07.674 --> 00:02:10.514
如果 X 中的某列虚拟变量有很多 1

00:02:10.514 --> 00:02:12.599
那就说明该组数据

00:02:12.599 --> 00:02:17.639
有希望存在足够的可变性 与其他类别进行区分

00:02:17.639 --> 00:02:19.769
与之相对 如果某列虚拟变量只有三个 1

00:02:19.770 --> 00:02:22.020
那很可能意味着 该列特征很难用于

00:02:22.020 --> 00:02:25.545
预测某个连续的目标变量

00:02:25.544 --> 00:02:29.554
而这样的特征也很可能是 模型出现过拟合的原因

00:02:29.555 --> 00:02:33.580
这里又是对数据进行测试集和训练集的划分

00:02:33.580 --> 00:02:34.830
训练模型

00:02:34.830 --> 00:02:37.650
我们使用的是经过筛选的 X

00:02:37.650 --> 00:02:41.250
然后把 R 平方值追加到这个列表里

00:02:41.250 --> 00:02:44.729
对不同规模的 X 矩阵迭代这一流程

00:02:44.729 --> 00:02:50.699
下面的代码会绘制出一个图表

00:02:50.699 --> 00:02:52.414
如果你想画的话 (通过 plot 参数控制)

00:02:52.414 --> 00:02:56.129
最后 函数会返回所有的 R 平方值 包括训练集和测试集的评分

00:02:56.129 --> 00:03:00.000
还会返回线性模型

00:03:00.000 --> 00:03:02.324
表现最好模型对应的 X_train、X_test、y_train、y_test

00:03:02.324 --> 00:03:05.414
表现最好模型对应的 X_train、X_test、y_train、y_test

00:03:05.414 --> 00:03:09.789
这部分只会返回表现最好的那一组数据集

00:03:09.789 --> 00:03:16.079
对于不同截断点创建的不同数据集来说

00:03:16.080 --> 00:03:23.518
这里就是 根据 best_cutoff 筛选 X 矩阵

00:03:23.518 --> 00:03:29.360
根据上面这句代码选出测试集 R 平方最大值对应的截断点

00:03:29.360 --> 00:03:32.600
因为我们在意的是模型在新数据 (测试集) 上的扩展性

00:03:32.599 --> 00:03:33.810
希望大家能理解

00:03:33.810 --> 00:03:37.045
这个函数在后台完成了什么操作

00:03:37.044 --> 00:03:39.069
再次运行这里的代码

00:03:39.069 --> 00:03:41.799
传入所有的 X 和 y

00:03:41.800 --> 00:03:45.445
然后它会返回表现最好的部分

00:03:45.444 --> 00:03:50.174
还有所有截断点对应的 R 平方值

00:03:50.175 --> 00:03:52.395
这个值越高

00:03:52.395 --> 00:03:54.270
再说一下截断点的意义

00:03:54.270 --> 00:03:57.330
这是一列中最少要包含的 1 值的数量

00:03:57.330 --> 00:04:00.165
也就是说 这个值越高

00:04:00.164 --> 00:04:03.049
模型包含的特征就越少

00:04:03.050 --> 00:04:08.700
值越小 X 中的特征就越多

00:04:08.699 --> 00:04:10.769
因为函数要对这些值进行迭代

00:04:10.770 --> 00:04:12.135
所以运行需要一些时间

00:04:12.134 --> 00:04:14.579
不过 最后你应该能够看到这样的结果

00:04:14.580 --> 00:04:17.115
可以看到 一开始随着特征数量的增加

00:04:17.115 --> 00:04:19.965
模型的表现会越来越好 直到某个点

00:04:19.964 --> 00:04:23.429
当你向 X 矩阵中加入太多特征时

00:04:23.430 --> 00:04:27.375
模型就开始出现过拟合 测试集上的表现开始下降

00:04:27.375 --> 00:04:30.990
事实上 如果你在这里减少更多值

00:04:30.990 --> 00:04:32.699
比如将其修改为 20

00:04:32.699 --> 00:04:36.735
测试集的线条会直线下滑

00:04:36.735 --> 00:04:42.180
训练集上的表现可能还会上升 甚至到达 1

00:04:42.180 --> 00:04:43.280
但在测试集上

00:04:43.279 --> 00:04:47.399
就会出现急剧地下滑 甚至出现负值

00:04:47.399 --> 00:04:50.579
不过 这里看到的趋势其实是 R 平方值评分的常见模式

00:04:50.579 --> 00:04:54.134
如果是均方误差 你很可能会看到相反方向的趋势

00:04:54.134 --> 00:04:57.719
重要的是 我们在乎的是模型在测试集上的表现

00:04:57.720 --> 00:05:03.125
表现最好的模型以及数据集 是在这几个变量中

00:05:03.125 --> 00:05:06.814
接下来就可以回答下面的问题了

00:05:06.814 --> 00:05:09.844
因为我们使用的是岭回归

00:05:09.845 --> 00:05:15.680
最好的评估特征重要性的方法其实

00:05:15.680 --> 00:05:18.769
就是看每个特征系数的权重

00:05:18.769 --> 00:05:21.402
因为特征都经过了标准化处理

00:05:21.403 --> 00:05:25.040
所以只要比较系数的大小就可以了

00:05:25.040 --> 00:05:29.675
值的正负说明方向

00:05:29.675 --> 00:05:35.180
方向是指 特征变量对预测变量的影响是正面的反面的

00:05:35.180 --> 00:05:37.189
绝对值大小代表的是

00:05:37.189 --> 00:05:40.295
标准化之后的特征影响程度

00:05:40.295 --> 00:05:45.020
可以看到 对于开发者来说

00:05:45.019 --> 00:05:49.814
居住国家以及工作年限 都是对工资影响较大的因素

00:05:49.814 --> 00:05:54.230
但并不是说 工作的时间越长

00:05:54.230 --> 00:05:56.460
工资就会越高

00:05:56.459 --> 00:05:59.479
好像工作经验 18-19 年对工资的影响要比 20 年及以上的高

00:05:59.480 --> 00:06:03.230
好像工作经验 18-19 年对工资的影响要比 20 年及以上的高

00:06:03.230 --> 00:06:09.975
工作经验 12-13 年的比 19-20 年的影响要高

00:06:09.975 --> 00:06:12.080
并且还高于 13-14 年的

00:06:12.079 --> 00:06:14.479
还高于 15-16 年的

00:06:14.480 --> 00:06:18.980
也就是说 年限和影响强度不是线性的关系

00:06:18.980 --> 00:06:21.920
你还会发现 作为开发者

00:06:21.920 --> 00:06:25.069
居住地也会对工资有很大影响

00:06:25.069 --> 00:06:27.589
某些国家的开发者工资

00:06:27.589 --> 00:06:31.214
要比其他国家高

00:06:31.214 --> 00:06:34.669
这些看上去是最重要的两个特征

00:06:34.670 --> 00:06:36.500
好的

00:06:36.500 --> 00:06:39.964
你可以用刚刚分析的信息来完成这里的一些练习

00:06:39.964 --> 00:06:44.224
这节课最重要的内容其实是这个图表

00:06:44.225 --> 00:06:46.595
以及它揭示的现象

00:06:46.595 --> 00:06:49.870
并不是特征越多

00:06:49.870 --> 00:06:53.757
模型就能获得更好的表现

00:06:53.757 --> 00:06:57.620
你应该用那些跟目标变量相关的特征

00:06:57.620 --> 00:07:01.879
作为模型的预测变量

00:07:01.879 --> 00:07:06.305
如果向模型中盲目添加特征

00:07:06.305 --> 00:07:09.319
最终会造成过拟合

00:07:09.319 --> 00:07:13.040
使模型没办法扩展到新的数据

00:07:13.040 --> 00:07:15.170
只能在训练集上表现良好

