WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:01.530
下面介绍下个任务

00:00:01.530 --> 00:00:05.040
如果某个用户

00:00:05.040 --> 00:00:08.759
没有关联超过 2 部电影的数组

00:00:08.759 --> 00:00:10.890
那么我们不会将他们保留在数据集中

00:00:10.890 --> 00:00:13.179
因为不需要判断他们与谁相关

00:00:13.179 --> 00:00:15.509
我们应该使用其他方法

00:00:15.509 --> 00:00:17.730
而不是协同过滤方法

00:00:17.730 --> 00:00:20.730
向这些用户推荐电影

00:00:20.730 --> 00:00:22.800
为了删除这些用户

00:00:22.800 --> 00:00:26.250
我将设置另一个字典

00:00:26.250 --> 00:00:30.554
该字典会存储 movies_seen 字典中电影超过 2 部的数组值

00:00:30.554 --> 00:00:34.450
字典名称设为 movies_to_analyze

00:00:34.450 --> 00:00:36.770
在此单元格结束时将返回该字典

00:00:36.770 --> 00:00:38.945
下面创建 for 循环

00:00:38.945 --> 00:00:45.960
for user_id, movies in movies_seen.items()

00:00:47.240 --> 00:00:50.429
之前是在 Python2 里添加项目

00:00:50.429 --> 00:00:53.070
现在是在 Python3 中添加项目

00:00:53.070 --> 00:00:57.265
如果 movies 的长度大于下限

00:00:57.265 --> 00:01:03.299
那么会将它附加到 movies_to _analyze 上

00:01:03.299 --> 00:01:10.905
我将传入键 即 user_id 并附加该 movies

00:01:10.905 --> 00:01:13.924
否则删除它

00:01:13.924 --> 00:01:16.099
这样就可以了

00:01:16.099 --> 00:01:18.324
运行时间很长

00:01:18.325 --> 00:01:21.560
在下一部分

00:01:21.560 --> 00:01:24.424
我们将查看这些用户之间的关系

00:01:24.424 --> 00:01:29.209
也就是说 我们将查看 user1 看过的电影

00:01:29.209 --> 00:01:31.250
并查看 user2 看过的电影

00:01:31.250 --> 00:01:32.915
当他们看过相同的电影时

00:01:32.915 --> 00:01:36.635
我们将评估他们之间的关系如何

00:01:36.635 --> 00:01:42.775
我们将提取 user1 看过的电影

00:01:42.775 --> 00:01:44.802
我们将从刚刚创建的字典中进行提取

00:01:44.802 --> 00:01:47.390
传入这个 user1

00:01:47.390 --> 00:01:50.560
提取出他看过的电影并存储到 movies1 中

00:01:50.560 --> 00:01:52.629
movies2 也一样

00:01:52.629 --> 00:01:55.109
我们获得了两个电影集合

00:01:55.109 --> 00:01:58.655
为了查看他们都看过的电影

00:01:58.655 --> 00:02:00.814
我们可以使用 intersect1d()

00:02:00.814 --> 00:02:03.819
如果你学习过数据科学课程

00:02:03.819 --> 00:02:06.219
就会在 Juno 的课程中见过 intersect1d()

00:02:06.219 --> 00:02:13.764
通过它可以快速获取这两个数组之间的交集

00:02:13.764 --> 00:02:15.309
还可以进一步提高速度

00:02:15.310 --> 00:02:17.090
在这里输入 =true

00:02:17.090 --> 00:02:19.450
这对于我们的示例来说没问题

00:02:19.449 --> 00:02:20.560
如果不为 true

00:02:20.560 --> 00:02:22.270
那么不应该添加进来

00:02:22.270 --> 00:02:25.180
=true 使代码运行速度更快

00:02:25.180 --> 00:02:28.659
接下来

00:02:28.659 --> 00:02:32.314
我将创建这个 DataFrame

00:02:32.314 --> 00:02:39.889
并提取每个用户所在的行和相似电影的位置

00:02:39.889 --> 00:02:41.959
我将提取所有这些评分

00:02:41.960 --> 00:02:47.115
我将存储两个数组 即这个 DataFrame

00:02:47.115 --> 00:02:53.460
每行代表一个用户 每列代表匹配的电影

00:02:53.460 --> 00:02:55.159
填充的是一个密集矩阵

00:02:55.159 --> 00:02:59.840
其中包含每部电影的评分

00:02:59.840 --> 00:03:01.250
这将是一个 DataFrame

00:03:01.250 --> 00:03:05.729
我们将从原始矩阵 user_by_movie 中提取数据

00:03:05.729 --> 00:03:09.084
这是一个很稀疏的矩阵

00:03:09.085 --> 00:03:14.865
我们要提取出 user1 和 user2 所在的行

00:03:14.865 --> 00:03:17.915
我们要提取他们的相似电影 即这个交集部分

00:03:17.914 --> 00:03:22.849
我们将提取这些部分的位置

00:03:22.849 --> 00:03:26.359
我在 Stack Overflow 帖子中找到了

00:03:26.360 --> 00:03:28.020
这个计算相关性的方法

00:03:28.020 --> 00:03:31.310
你可以使用之前的函数

00:03:31.310 --> 00:03:35.030
但是使用 NumPy 运算方法速度更快

00:03:35.030 --> 00:03:40.759
我们将使用 transpose().corr() 它会返回一个网格

00:03:40.759 --> 00:03:43.560
你可以对任何 DataFrame

00:03:43.560 --> 00:03:44.920
运行这个 df.transpose().corr()

00:03:44.919 --> 00:03:48.189
它将返回所有列之间的关系

00:03:48.189 --> 00:03:50.389
transpose() 会接受用户

00:03:50.389 --> 00:03:53.574
将他们从行中移到列中

00:03:53.574 --> 00:03:56.449
corr() 会计算两个用户之间的关系

00:03:56.449 --> 00:03:58.909
结果是一个矩阵

00:03:58.909 --> 00:04:02.039
对角线上的值都为 1 因为它们表示每列与本身的关系

00:04:02.039 --> 00:04:05.449
非对角线上的值表示成对的关系

00:04:05.449 --> 00:04:11.149
现在我们可以计算任何两个用户之间的关系了

00:04:11.150 --> 00:04:13.670
这是任何两个用户之间的关系

00:04:13.669 --> 00:04:16.789
我们可以对所有可能的用户对完成这一计算流程

00:04:16.790 --> 00:04:18.785
对所有的用户对运行此 compute_correlation() 函数

00:04:18.785 --> 00:04:22.470
获取它们之间的相关系数

00:04:22.470 --> 00:04:24.830
这就是这个 pickle 的作用

00:04:24.829 --> 00:04:29.300
它存储的是传入的两个用户对应的列以及他们的关系

00:04:29.300 --> 00:04:34.199
这里针对的是所有的用户对

