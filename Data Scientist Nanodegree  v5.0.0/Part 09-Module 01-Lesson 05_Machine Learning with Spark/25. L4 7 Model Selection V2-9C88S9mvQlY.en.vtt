WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:05.025
Spark supports both random splits and k-fold cross-validation.

00:00:05.025 --> 00:00:07.470
Let's just start with general splits.

00:00:07.469 --> 00:00:10.230
With the method name exactly the same,

00:00:10.230 --> 00:00:13.200
we can break the data frame into two parts.

00:00:13.199 --> 00:00:15.644
So, for example in this case,

00:00:15.644 --> 00:00:21.179
it depends until the data goes to train and 20 percent to test.

00:00:21.179 --> 00:00:24.960
If we want to create really friends subsets for training, testing,

00:00:24.960 --> 00:00:29.789
and validation, we can just call this method again on the second part.

00:00:29.789 --> 00:00:32.655
So, we could do something like this.

00:00:32.655 --> 00:00:38.039
First, break the dataset into train with 60 percent

00:00:38.039 --> 00:00:43.704
of the data and then the rest gets 40 percent,

00:00:43.704 --> 00:00:49.984
and then split the rest 50-50 percent to test and validation.

00:00:49.984 --> 00:00:55.975
This way, the train set will have 60 percent of the original DataFrame,

00:00:55.975 --> 00:01:00.920
test and validation both 20-20 percent of the original data.

00:01:00.920 --> 00:01:02.840
By fixing the randomSplit,

00:01:02.840 --> 00:01:06.305
we can also make sure that the split is reproducible.

00:01:06.305 --> 00:01:11.510
However, common these throughout and we are just use train and test,

00:01:11.510 --> 00:01:16.730
to train the logistic regression model we used before.

00:01:16.730 --> 00:01:21.530
So here is the pipeline we used in the previous video,

00:01:21.530 --> 00:01:26.900
now we can train on the train set only.

00:01:26.900 --> 00:01:31.984
One similarly strain, we can just transform the test set.

00:01:31.984 --> 00:01:35.015
Since we did a random split,

00:01:35.015 --> 00:01:40.939
the first checkered is a different one than the one we are used to,

00:01:40.939 --> 00:01:43.864
but we certainly got the prediction here.

00:01:43.864 --> 00:01:49.204
So let's see how well this model did on the training set.

00:01:49.204 --> 00:01:53.855
So we have the correct label for

00:01:53.855 --> 00:02:00.395
about 7,700 of the 20,000 records we have,

00:02:00.394 --> 00:02:03.640
I'll just save what that number is.

00:02:03.640 --> 00:02:08.460
So our accuracy is around 30 percent,

00:02:08.460 --> 00:02:13.025
that's a lot worse than what we saw earlier.

00:02:13.025 --> 00:02:19.655
But at least now we have a more realistic idea about the accuracy of our model.

00:02:19.655 --> 00:02:24.890
For k-fold cross-validation, we can use the cross-validation method.

00:02:24.889 --> 00:02:27.884
In the cross-validatior parameters,

00:02:27.884 --> 00:02:31.254
we can specify the estimator we would like to use,

00:02:31.254 --> 00:02:34.879
and that's going to be our pipeline from earlier.

00:02:34.879 --> 00:02:38.810
The parameter grid, if we want to do a quick search on

00:02:38.810 --> 00:02:43.354
a setup parameter combinations, the evaluator,

00:02:43.354 --> 00:02:49.994
in our case that should be the multi-class classification evaluator,

00:02:49.995 --> 00:02:53.000
as well as the number of faults of course.

00:02:53.000 --> 00:02:58.705
In each fault, the one over num faults,

00:02:58.705 --> 00:03:01.274
part of the data goes into testing,

00:03:01.274 --> 00:03:03.110
the rest is used for training.

00:03:03.110 --> 00:03:07.190
So for example if we choose the value of three,

00:03:07.189 --> 00:03:12.050
then we will train our model on two-thirds of

00:03:12.050 --> 00:03:18.830
the data and keep one third as a test set and repeat this process three times.

00:03:18.830 --> 00:03:21.020
For the parameter grid,

00:03:21.020 --> 00:03:26.825
we can try to experiment with the number of words we keep in our TF-IDF features.

00:03:26.824 --> 00:03:31.634
So let's try 10 and 20,000 words.

00:03:31.634 --> 00:03:38.500
So, since it was three fold cross validation and we have these two parameters,

00:03:38.500 --> 00:03:42.365
we will need to train six models into all.

00:03:42.365 --> 00:03:43.909
Okay let's see.

00:03:43.909 --> 00:03:48.539
Was there typos did I make?

00:03:52.479 --> 00:03:56.685
Okay, training all these six models,

00:03:56.685 --> 00:03:58.729
we have taken a little bit longer.

00:03:58.729 --> 00:04:02.704
But let's just run this and wait.

00:04:02.705 --> 00:04:05.350
Once the training is done,

00:04:05.349 --> 00:04:10.579
we can check the average performance of the parameter set.

00:04:10.580 --> 00:04:15.440
It seems that doubling the number of words only slightly improved the results,

00:04:15.439 --> 00:04:20.459
so we have an accuracy just below

00:04:20.459 --> 00:04:26.889
37 percent and a little bit over 37 percent.

00:04:26.889 --> 00:04:33.784
We can also check the accuracy of the test set.

00:04:33.785 --> 00:04:36.180
So in this particular case,

00:04:36.180 --> 00:04:41.600
we see a slightly higher number of correct predictions than before.

