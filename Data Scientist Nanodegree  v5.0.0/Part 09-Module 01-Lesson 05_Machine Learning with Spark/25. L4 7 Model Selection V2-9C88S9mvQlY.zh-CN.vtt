WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:05.025
Spark 支持 randomSplit 和 k-fold cross-validation 两种验证方式

00:00:05.025 --> 00:00:07.470
让我们先看一下 randomSplit

00:00:07.469 --> 00:00:10.230
与方法名称完全相同

00:00:10.230 --> 00:00:13.200
我们可以将 dataframe 分为两部分

00:00:13.199 --> 00:00:15.644
在这种情况下

00:00:15.644 --> 00:00:21.179
80% 的数据用于训练 20％的数据用于测试

00:00:21.179 --> 00:00:24.960
如果我们想创建三个子数据集用于训练  测试 

00:00:24.960 --> 00:00:29.789
和验证 我们可以用两次这个方法

00:00:29.789 --> 00:00:32.655
我们可以做这么做

00:00:32.655 --> 00:00:38.039
首先 将数据集的 60％  用于训练

00:00:38.039 --> 00:00:43.704
然后剩下的 40％ 进行第二次拆分

00:00:43.704 --> 00:00:49.984
将剩下的数据五五分成测试和验证

00:00:49.984 --> 00:00:55.975
这样 训练数据将拥有原始DataFrame的60％，

00:00:55.975 --> 00:01:00.920
测试和验证各拥有 20％ 的原始数据

00:01:00.920 --> 00:01:02.840
让随机种子不变

00:01:02.840 --> 00:01:06.305
我们可以确保每次分割的数据是相同的

00:01:06.305 --> 00:01:11.510
我们把这两列给注释掉 只保留训练集和测试集

00:01:11.510 --> 00:01:16.730
来训练之前用过的逻辑回归模型

00:01:16.730 --> 00:01:21.530
这是我们上一个视频中使用的管道

00:01:21.530 --> 00:01:26.900
现在我们只能在训练集上训练模型了

00:01:26.900 --> 00:01:31.984
模型训练好之后  我们可以对测试集进行变换

00:01:31.984 --> 00:01:35.015
由于我们做了 randomSplit

00:01:35.015 --> 00:01:40.939
第一行记录的结果与我们之前看到的不同

00:01:40.939 --> 00:01:43.864
不过我们也会有预测结果

00:01:43.864 --> 00:01:49.204
那么让我们看看这个模型在训练集上的表现如何

00:01:49.204 --> 00:01:53.855
正确的标签

00:01:53.855 --> 00:02:00.395
占了 20,000 条记录中的 7,700 条

00:02:00.394 --> 00:02:03.640
好了让我们看看准确率是多少

00:02:03.640 --> 00:02:08.460
我们的准确率大约是 30％

00:02:08.460 --> 00:02:13.025
这比之前的结果要糟糕得多

00:02:13.025 --> 00:02:19.655
但至少现在我们对模型的准确性有一个更现实的看法

00:02:19.655 --> 00:02:24.890
对于k-fold cross-validation 我们可以使用 CrossValidator 这个方法

00:02:24.889 --> 00:02:27.884
在 CrossValidator 参数中

00:02:27.884 --> 00:02:31.254
我们可以指定想要使用的估算器

00:02:31.254 --> 00:02:34.879
这里写的是我们之前的管道

00:02:34.879 --> 00:02:38.810
如果我们想针对参数组合使用网格搜索的话 这里就写 paramGrid

00:02:38.810 --> 00:02:43.354
Evaluator 参数

00:02:43.354 --> 00:02:49.994
我们这里就写多级分类评估器

00:02:49.995 --> 00:02:53.000
还有这里的  numfolds 进行多少次交叉验证

00:02:53.000 --> 00:02:58.705
在每此验证中 1/numFolds 的数据

00:02:58.705 --> 00:03:01.274
会成为测试集

00:03:01.274 --> 00:03:03.110
其余的用于训练

00:03:03.110 --> 00:03:07.190
例如 如果我们写 3 

00:03:07.189 --> 00:03:12.050
那么三分之二的数据会变成训练集

00:03:12.050 --> 00:03:18.830
三分之一的数据作为测试集 并重复此过程三次

00:03:18.830 --> 00:03:21.020
对于 paramGrid 来说

00:03:21.020 --> 00:03:26.825
我们用在 TF-IDF 中保留的单词数量

00:03:26.824 --> 00:03:31.634
我们尝试一下 10000 和20000个单词

00:03:31.634 --> 00:03:38.500
由于进行了三次交叉验证 同时我们有这两个参数

00:03:38.500 --> 00:03:42.365
所以我们一共需要训练六种模型

00:03:42.365 --> 00:03:43.909
好的 让我们看看

00:03:43.909 --> 00:03:48.539
写错了吗 

00:03:52.479 --> 00:03:56.685
好的 训练这六个模型

00:03:56.685 --> 00:03:58.729
会花一点时间

00:03:58.729 --> 00:04:02.704
运行它并等待

00:04:02.705 --> 00:04:05.350
训练完成后

00:04:05.349 --> 00:04:10.579
我们看看这两个参数的平均效果

00:04:10.580 --> 00:04:15.440
似乎将单词数量加倍只能略微改善结果

00:04:15.439 --> 00:04:20.459
一个准确性

00:04:20.459 --> 00:04:26.889
略低于 37％ 另一个略高于 37％ 

00:04:26.889 --> 00:04:33.784
我们还可以看一下测试集的准确率

00:04:33.785 --> 00:04:36.180
这个案例中

00:04:36.180 --> 00:04:41.600
正确预测数量比以前略高

