WEBVTT
Kind: captions
Language: zh-CN

00:00:04.549 --> 00:00:07.049
在录制这个视频时

00:00:07.049 --> 00:00:10.289
Spark 的最新版本 2.2.1

00:00:10.289 --> 00:00:12.613
同时支持两个机器学习库

00:00:12.614 --> 00:00:15.015
Spark ML 和 Spark MLlib

00:00:15.015 --> 00:00:18.103
Spark MLlib 是一个基于 RDD 的库

00:00:18.103 --> 00:00:21.585
它自2.2版开始已进入维护模式

00:00:21.585 --> 00:00:23.475
根据目前的规划

00:00:23.475 --> 00:00:26.115
Spark ML 即基于 DataFrames 的 API

00:00:26.114 --> 00:00:28.859
的功能将在2.3版本中得到完善

00:00:28.859 --> 00:00:33.329
在这之后 Spark MLlib 将从 Spark 3.0 中删除

00:00:33.329 --> 00:00:36.854
所以目前 我们会混搭着使用这两个库

00:00:36.854 --> 00:00:38.129
但之后 

00:00:38.130 --> 00:00:40.020
因为 Spark ML 会慢慢变成 Spark 的标准机器学习库

00:00:40.020 --> 00:00:43.455
所以你要把重心放在这个库上

00:00:43.454 --> 00:00:45.979
就像 Spark DataFrames 的设计和

00:00:45.979 --> 00:00:48.199
Python 以及 R 的 DataFrames 很像 

00:00:48.200 --> 00:00:51.020
Spark ML 库设计的和 Scikit-learn 很像

00:00:51.020 --> 00:00:54.560
它提供的管道可以让我们把数据清洗

00:00:54.560 --> 00:00:59.420
特征工程的步骤和模型训练以及预测缝合在一起

00:00:59.420 --> 00:01:05.155
通常来讲 Spark 提供用来处理与输入数据大小成线性比例的算法的支持

00:01:05.155 --> 00:01:08.480
在库里 可以找到对最常见

00:01:08.480 --> 00:01:12.469
线性算法的支持 如线性和逻辑回归

00:01:12.469 --> 00:01:15.260
随机森林和 k 均值聚类

00:01:15.260 --> 00:01:19.355
Spark ML 还有用于特征计算

00:01:19.355 --> 00:01:22.640
调参和模型评估的工具

00:01:22.640 --> 00:01:25.519
然后我们想到分布式机器学习

00:01:25.519 --> 00:01:28.734
有两种不同的方法可以实现并行化

00:01:28.734 --> 00:01:31.909
数据并行化和任务并行化

00:01:31.909 --> 00:01:34.280
我们可以使用大型数据集

00:01:34.280 --> 00:01:37.685
以并行的方式把同一模型放在数据集的子集上进行训练

00:01:37.685 --> 00:01:39.850
这是 Spark 之前的处理方式。

00:01:39.849 --> 00:01:42.890
DAG 程序会充当

00:01:42.890 --> 00:01:47.704
大多数算法的服务器，每个部分结果的迭代会被汇总

00:01:47.704 --> 00:01:50.629
我们也可以同时在多台机器上并行训练模型

00:01:50.629 --> 00:01:54.724
每份数据集足以塞进一台机器

00:01:54.724 --> 00:01:58.489
我们将在超参数调优部分介绍Spark目前和以后

00:01:58.489 --> 00:02:03.299
并行训练模型的选项

