WEBVTT
Kind: captions
Language: zh-CN

00:00:03.980 --> 00:00:08.699
我们已经给所有的特征创建了数值型的变量

00:00:08.699 --> 00:00:11.439
我们可以训练我们的第一个机器学习算法了

00:00:11.439 --> 00:00:13.859
首先 我们来看看监督式算法

00:00:13.859 --> 00:00:17.644
这种算法使用的是打过标签的数据集进行训练

00:00:17.644 --> 00:00:21.910
至于是做分类还是回归任务

00:00:21.910 --> 00:00:23.524
取决于给数据打的标签是什么

00:00:23.524 --> 00:00:26.609
如果标签代表类别 例如

00:00:26.609 --> 00:00:29.929
升级的用户与降级的用户

00:00:29.929 --> 00:00:32.810
这时我们就在处理一个分类问题

00:00:32.810 --> 00:00:36.260
我们要在预先确定好的所有可能情况中预测出最可能的结果

00:00:36.259 --> 00:00:39.864
如果我们的标签是连续值 例如

00:00:39.865 --> 00:00:43.730
特定用户在某一天收听了多少首歌曲

00:00:43.729 --> 00:00:45.829
我们就是在处理回归问题了

00:00:45.829 --> 00:00:48.079
让我们从分类问题开始

00:00:48.079 --> 00:00:51.019
Spark 支持最常用的算法

00:00:51.020 --> 00:00:55.925
二元和多分类 如逻辑回归

00:00:55.924 --> 00:00:58.820
随机森林 梯度提升树 

00:00:58.820 --> 00:01:02.215
支持向量机和朴素贝叶斯

00:01:02.215 --> 00:01:05.180
对于回归  Spark 有内置方法

00:01:05.180 --> 00:01:08.705
来处理线性和广义线性回归

00:01:08.704 --> 00:01:11.524
和基于树的回归

00:01:11.525 --> 00:01:14.450
所有这些算法都有详细的文档

00:01:14.450 --> 00:01:17.719
在文档里你可以找到更多关于这些算法的参数的描述

00:01:17.719 --> 00:01:21.584
如果你想引用scikit-learn 的算法

00:01:21.584 --> 00:01:26.750
你要确保参数的意义相同

00:01:26.750 --> 00:01:31.040
即便如此 你可能还会发现性能有所差异

00:01:31.040 --> 00:01:36.510
因为损失优化器在不同工具中实现方式有所不同

