WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.234
作为分类问题的一个例子

00:00:03.234 --> 00:00:06.540
我们要预测问题的标签是什么

00:00:06.540 --> 00:00:10.064
对于这个任务 我们会使用 onetag 字段

00:00:10.064 --> 00:00:13.859
我在之前的视频中已经介绍过了

00:00:13.859 --> 00:00:19.689
Onetag 是问题中最常见的标签

00:00:19.690 --> 00:00:26.655
这样我们就可以把多目标问题简化为单个目标问题

00:00:26.655 --> 00:00:34.655
我们会使用之前视频中计算出的 TF-IDF 作为特征 

00:00:34.655 --> 00:00:38.359
然后训练一个基本的逻辑回归模型

00:00:38.359 --> 00:00:45.045
如果你还记得 我们之前从 onetag 列创建了标签列

00:00:45.045 --> 00:00:52.385
Label列有数值 TF-IDF已经是稀疏向量

00:00:52.384 --> 00:00:57.104
这直接可以当作模型的输入了

00:00:57.104 --> 00:01:02.299
数据集有 301 个不同的标签

00:01:02.299 --> 00:01:05.149
所以 我们的模型要判断哪个标签是

00:01:05.150 --> 00:01:08.245
特定问题最可能的标签

00:01:08.245 --> 00:01:12.175
好的我们的模型已经训练好了

00:01:12.174 --> 00:01:15.439
现在 我们来看看它的参数

00:01:15.439 --> 00:01:19.039
因为我们在处理多类分类问题

00:01:19.040 --> 00:01:25.150
我们将有一个系数矩阵 而不仅仅是一个系数向量

00:01:25.150 --> 00:01:30.155
单个截距值也会变成截距向量

00:01:30.155 --> 00:01:35.510
我们有一个 301 行 1000列的矩阵

00:01:35.510 --> 00:01:40.195
以及截距向量

00:01:40.194 --> 00:01:43.639
接下来我们看看模型的准确率

00:01:43.640 --> 00:01:46.290
好吧 我们只用了

00:01:46.290 --> 00:01:50.150
TF-IDF处理最常见的 1000 个单词

00:01:50.150 --> 00:01:54.340
但我们的准确率约为 36％

00:01:54.340 --> 00:01:56.555
那么这个结果怎么样 ？ 

00:01:56.555 --> 00:02:01.610
我们的数据集中有大约 100,000 行

00:02:01.609 --> 00:02:05.260
和 301 个不同的标签

00:02:05.260 --> 00:02:10.444
如果标签在我们的数据集中均匀分布

00:02:10.444 --> 00:02:18.745
随机猜中右侧标签的概率是1/301

00:02:18.745 --> 00:02:21.935
也就是大约3％的猜中概率

00:02:21.935 --> 00:02:26.550
但数据集里有些标签肯定比其他标签更常见

00:02:26.550 --> 00:02:32.854
最常见的标签大约占了记录的5％

00:02:32.854 --> 00:02:36.030
所以 36％ 准确率还是不错的

00:02:36.030 --> 00:02:39.724
我们还可以把更多的特征加进来

00:02:39.724 --> 00:02:43.405
不同的模型参数可能会对结果有所改善

00:02:43.405 --> 00:02:46.759
但是这块内容我们下次再讲吧

00:02:46.759 --> 00:02:53.489
我还想再提一下 我们是用的

00:02:53.490 --> 00:02:54.985
训练集做的预测 这个操作是不对的

00:02:54.985 --> 00:02:58.510
这个结果可能有点过于乐观了

00:02:58.509 --> 00:03:01.870
后面的视频里我们会演示正确的操作

