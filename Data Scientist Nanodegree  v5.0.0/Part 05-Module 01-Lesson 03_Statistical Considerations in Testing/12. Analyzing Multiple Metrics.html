<!-- udacity2.0 -->
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Analyzing Multiple Metrics</title>
  <link rel="stylesheet" href="../assets/css/bootstrap.min.css">
  <link rel="stylesheet" href="../assets/css/plyr.css">
  <link rel="stylesheet" href="../assets/css/katex.min.css">
  <link rel="stylesheet" href="../assets/css/jquery.mCustomScrollbar.min.css">
  <link rel="stylesheet" href="../assets/css/styles.css">
  <link rel="shortcut icon" type="image/png" href="../assets/img/udacimak.png" />
</head>

<body>
  <div class="wrapper">
    <nav id="sidebar">
  <div class="sidebar-header">
    <h3>Statistical Considerations in Testing</h3>
  </div>

  <ul class="sidebar-list list-unstyled CTAs">
    <li>
      <a href="../index.html" class="article">Back to Home</a>
    </li>
  </ul>

  <ul class="sidebar-list list-unstyled components">
    <li class="">
      <a href="01. Lesson Introduction.html">01. Lesson Introduction</a>
    </li>
    <li class="">
      <a href="02. Practice Statistical Significance.html">02. Practice: Statistical Significance</a>
    </li>
    <li class="">
      <a href="03. Statistical Significance - Solution.html">03. Statistical Significance - Solution</a>
    </li>
    <li class="">
      <a href="04. Practical Significance.html">04. Practical Significance</a>
    </li>
    <li class="">
      <a href="05. Experiment Size.html">05. Experiment Size</a>
    </li>
    <li class="">
      <a href="06. Experiment Size - Solution.html">06. Experiment Size - Solution</a>
    </li>
    <li class="">
      <a href="07. Using Dummy Tests.html">07. Using Dummy Tests</a>
    </li>
    <li class="">
      <a href="08. Non-Parametric Tests Part I.html">08. Non-Parametric Tests Part I</a>
    </li>
    <li class="">
      <a href="09. Non-Parametric Tests Part I - Solution.html">09. Non-Parametric Tests Part I - Solution</a>
    </li>
    <li class="">
      <a href="10. Non-Parametric Tests Part II.html">10. Non-Parametric Tests Part II</a>
    </li>
    <li class="">
      <a href="11. Non-Parametric Tests Part II - Solution.html">11. Non-Parametric Tests Part II - Solution</a>
    </li>
    <li class="">
      <a href="12. Analyzing Multiple Metrics.html">12. Analyzing Multiple Metrics</a>
    </li>
    <li class="">
      <a href="13. Early Stopping.html">13. Early Stopping</a>
    </li>
    <li class="">
      <a href="14. Early Stopping - Solution.html">14. Early Stopping - Solution</a>
    </li>
    <li class="">
      <a href="15. Lesson Conclusion.html">15. Lesson Conclusion</a>
    </li>
  </ul>

  <ul class="sidebar-list list-unstyled CTAs">
    <li>
      <a href="../index.html" class="article">Back to Home</a>
    </li>
  </ul>
</nav>

    <div id="content">
      <header class="container-fluild header">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <div class="align-items-middle">
                <button type="button" id="sidebarCollapse" class="btn btn-toggle-sidebar">
                  <div></div>
                  <div></div>
                  <div></div>
                </button>

                <h1 style="display: inline-block">12. Analyzing Multiple Metrics</h1>
              </div>
            </div>
          </div>
        </div>
      </header>

      <main class="container">
        <div class="row">
          <div class="col-12">
            <div class="ud-atom">
  <h3><p>Analyzing Multiple Metrics Pt 1</p></h3>
  <video controls>
  <source src="12. Analyzing Multiple Metrics Pt 1-SNFHYbJvlZU.mp4" type="video/mp4">

  <track default="true" kind="subtitles" srclang="en" src="12. Analyzing Multiple Metrics Pt 1-SNFHYbJvlZU.en.vtt" label="en">
  <track default="false" kind="subtitles" srclang="BR" src="12. Analyzing Multiple Metrics Pt 1-SNFHYbJvlZU.pt-BR.vtt" label="BR">
  <track default="false" kind="subtitles" srclang="CN" src="12. Analyzing Multiple Metrics Pt 1-SNFHYbJvlZU.zh-CN.vtt" label="CN">
</video>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>

  <h4>Start Quiz:</h4>
  Unknown quiz type. Please contact the developer to make it compatible with this atom type!


</div>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3><p>Analyzing Multiple Metrics Pt 2</p></h3>
  <video controls>
  <source src="12. Analyzing Multiple Metrics Pt 2-x7foG7murvU.mp4" type="video/mp4">

  <track default="true" kind="subtitles" srclang="en" src="12. Analyzing Multiple Metrics Pt 2-x7foG7murvU.en.vtt" label="en">
  <track default="false" kind="subtitles" srclang="BR" src="12. Analyzing Multiple Metrics Pt 2-x7foG7murvU.pt-BR.vtt" label="BR">
  <track default="false" kind="subtitles" srclang="CN" src="12. Analyzing Multiple Metrics Pt 2-x7foG7murvU.zh-CN.vtt" label="CN">
</video>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <h2 id="analyzing-multiple-metrics">Analyzing Multiple Metrics</h2>
<p>If you're tracking multiple evaluation metrics, make sure that you're aware of <br />
how the Type I error rates on individual metrics can affect the overall chance <br />
of making some kind of Type I error. The simplest case we can consider is if we <br />
have <em>n</em> independent evaluation metrics, and that seeing one with a <br />
statistically significant result would be enough to call the manipulation a <br />
success. In this case, the probability of making at least one Type I error is <br />
given by <span class="mathquill ud-math">\alpha_{over} = 1 - (1-\alpha_{ind})^n</span>, <br />
illustrated in the below image for individual <br />
<span class="mathquill ud-math">\alpha_{ind} = .05</span> and <span class="mathquill ud-math">\alpha_{ind} = .01</span>:</p>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <figure class="figure">
    <img src="img/c08-multimetrics-01.png" alt="" class="img img-fluid">
    <figcaption class="figure-caption">
      
    </figcaption>
  </figure>
</div>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <p>To protect against this, we need to introduce a correction factor on the <br />
individual test error rate so that the overall error rate is at most the <br />
desired level. A conservative approach is to divide the overall error rate by <br />
the number of metrics tested:</p>
<p><span class="mathquill ud-math">\alpha_{ind} = \alpha_{over}/n</span></p>
<p>This is known as the <strong>Bonferroni correction</strong>. If we assume independence <br />
between metrics, we can do a little bit better with the <strong>Šidák correction</strong>:</p>
<p><span class="mathquill ud-math">\alpha_{ind} = 1-(1-\alpha_{over})^{1/n}</span></p>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <figure class="figure">
    <img src="img/c08-multimetrics-02.png" alt="The Šidák correction is only slightly higher than the line drawn by the Bonferroni correction." class="img img-fluid">
    <figcaption class="figure-caption">
      <p>The Šidák correction is only slightly higher than the line drawn by the Bonferroni correction.</p>
    </figcaption>
  </figure>
</div>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <p>In real life, evaluation scenarios are rarely so straightforward. Metrics will<br />
likely be correlated in some way, rather than being independent. If a positive<br />
correlation exists, then knowing the outcome of one metric will make it more<br />
likely for a correlated metric to also point in the same way. In this case, the<br />
corrections above will be more conservative than necessary, resulting in an<br />
overall error rate smaller than the desired level. (In cases of negative<br />
correlation, the true error rate could go either way, depending on the types of<br />
tests performed.)</p>
<p>In addition, we might need multiple metrics to show statistical significance to<br />
call an experiment a success, or there may be different degrees of success<br />
depending on which metrics appear to be moved by the manipulation. One metric<br />
may not be enough to make it worth deploying a change tested in an experiment.<br />
Reducing the individual error rate will make it harder for a truly significant<br />
effect to show up as statistically significant. That is, reducing the Type I error<br />
rate will also increase the Type II error rate – another conservative shift.</p>
<p>Ultimately, there is a small balancing act when it comes to selecting an<br />
error-controlling scheme. Being fully conservative with one of the simple<br />
corrections above means that you increase the risk of failing to roll out<br />
changes that actually have an impact on metrics. Consider the level of<br />
dependence between metrics and what results are needed to declare a success to<br />
calibrate the right balance in error rates. If you need to see a significant<br />
change in all of your metrics to proceed with it, you might not need a<br />
correction factor at all. You can also use dummy test results, bootstrapping,<br />
and permutation approaches to plan significance thresholds. Finally, don't<br />
forget that practical significance can be an all-important quality that<br />
overrides other statistical significance findings.</p>
<p>While the main focus of this page has been on interpretation of evaluation<br />
metrics, it's worth noting that these cautions also apply to invariant metrics.<br />
The more invariant metrics you test, the more likely it will be that some test<br />
will show a statistically significant difference even if the groups tested are<br />
drawn from equivalent populations. However, it might not be a good idea to<br />
apply a correction factor to individual tests since we want to avoid larger<br />
issues with interpretation later on. As mentioned previously, a single<br />
invariant metric showing a statistically significant difference is not<br />
necessarily cause for alarm, but it is something that merits follow-up in case<br />
it does have an effect on our analysis.</p>
</div>

</div>
<div class="divider"></div>
          </div>

          <div class="col-12">
            <p class="text-right">
              <a href="13. Early Stopping.html" class="btn btn-outline-primary mt-4" role="button">Next Concept</a>
            </p>
          </div>
        </div>
      </main>

      <footer class="footer">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <p class="text-center">
                <a href="https://us-udacity.github.io/" target="_blank">【udacity2.0 】If you need more courses, please add wechat：udacity6</a>
              </p>
            </div>
          </div>
        </div>
      </footer>
    </div>
  </div>


  <script src="../assets/js/jquery-3.3.1.min.js"></script>
  <script src="../assets/js/plyr.polyfilled.min.js"></script>
  <script src="../assets/js/bootstrap.min.js"></script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js"></script>
  <script src="../assets/js/katex.min.js"></script>
  <script>
    // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('12. Analyzing Multiple Metrics')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
</body>

</html>
